<strong>ADT (Abstract Data Type)</strong>: “무엇을 할 수 있는가”를 정의하는 <strong>행동 규약</strong> (예: <strong>스택</strong> = LIFO, <strong>큐</strong> = FIFO).

<strong>DS (Data Structure)</strong>: 그 규약을 만족하도록 실제로 <strong>저장·연결·탐색</strong>하는 <strong>구현 방식</strong> (예: <strong>배열</strong>, <strong>연결 리스트</strong>, <strong>원형 버퍼</strong> 등).

<strong>예</strong>: <strong>모델링(ADT)</strong>은 스택, <strong>구현(DS)</strong>은 “배열로 만든 스택”, “연결 리스트로 만든 스택” 등 다양하게 가능.

<details> <summary><strong>스택 (Stack)</strong></summary>

## 정의(ADT)

- <strong>LIFO(후입선출)</strong> 규칙을 가지는 선형 자료구조.

- 한쪽 끝에서만 삽입/삭제가 일어남.

- 최근 원소를 가리키는 멤버 top을 가짐(필드).

## 특징

- 입력·삭제 모두 <strong>한 방향</strong>에서 수행.

- <strong>pop( )</strong> 후 <strong>top</strong>은 <strong>그 직전 원소</strong>를 가리킴.

- <strong>배열/연결 리스트</strong> 등 여러 DS로 구현 가능.

## 대표 연산(메서드)

- `push(x)`: 맨 위에 삽입
- `pop()`: 맨 위 원소 제거+반환  
  ( 요소를 꺼내며 제거하는 연산, 자료구조마다 위치는 다름)

- `top()/peek()`: 맨 위 원소 조회
- `empty()`: 자료구조가 비어 있는지 확인
- `size()`: 자료구조에 들어 있는 요소의 개수를 반환

## 오류 케이스

- <strong>Underflow</strong>: 빈 스택에서 <code>pop</code>/<code>top</code>.

- <strong>Overflow</strong>: 고정 용량에서 한도를 초과한 <code>push</code>.

## 구현방식

- <strong>동적 배열</strong>: 캐시 친화적

- <strong>연결 리스트</strong>: 중간 조작 유리

## <strong>캐시 친화적인 이유</strong>:

CPU는 읽을 때 인접 메모리 블록까지 <strong>프리패치</strong>해 연속 접근이 빠름.

따라서 메모리 상에서 연속된 공간을 차지하는 동적 배열은  
지역성이 캐시 효율이 더 좋음

## 활용 예시

- 브라우저 <strong>뒤로가기</strong>
- <strong>실행 취소(Undo)</strong>
- <strong>후위 표기식 계산</strong>
- <strong>호출 스택</strong>

## Big-O

<strong>Push / Pop / Top</strong>: 평균 <strong>O(1)</strong>.

</details>
<details> <summary><strong>큐 (Queue)</strong></summary>

## 정의(ADT)

- <strong>FIFO(선입선출)</strong> 규칙을 가지는 선형 자료구조.

- 뒤(<strong>rear</strong>)로 삽입, 앞(<strong>front</strong>)에서 삭제 — <strong>입·출력 위치 분리</strong>.

## 특징

- <strong>front</strong>: 삭제/조회가 일어나는 위치(맨 앞).

- <strong>rear</strong>: 삽입이 일어나는 위치(맨 뒤).

- 먼저 들어온 데이터가 먼저 나가는 <strong>대기 행렬</strong>.

- <strong>배열 / 연결 리스트</strong> 등 여러 DS로 구현 가능.

## 대표 연산(메서드)

- <strong>`enqueue(x)`</strong>: 뒤(<strong>rear/back</strong>)에 삽입.

- <strong>`dequeue()`</strong>: 앞(<strong>front</strong>)에서 제거+반환.

- <strong>`front()` / `peek()`</strong>: 가장 앞 요소 조회(보존).

- <strong>`empty()`</strong>: 공백 여부

- <strong>`size()`</strong>()요소 수 확인.

## 오류 케이스

- <strong>Underflow</strong>: 빈 큐에서 <code>dequeue</code>.

- <strong>Overflow</strong>: 고정 용량에서 한도를 초과한 <code>enqueue</code>.

## 구현방식

### 단순 배열

- 구현이 간단함
- 인덱스가 정적으로 관리되어 인덱스 활용이 제한적  
  (front와 rear가 오직 증가만 하기 때문에 `dequeue` 연산으로 제거된 인덱스 재사용 불가)

  → <strong>원형 큐</strong>로 보완해 빈 칸을 재활용.

### 원형 큐

- rear와 front를 모듈러 연산(%, mod)으로 관리하여  
  인덱스가 순환하는 구조의 큐

- 인덱스 갱신:  
  rear = `(rear + 1) % capacity`  
  front = `(front + 1) % capacity`

- 크기 계산(현재 원소 개수):  
  size = `(rear - front + capacity) % capacity`

- isEmpty:  
  `size == 0`  
  `rear == front`

- isFull:  
  `size == capacity - 1`  
  `(rear+1) % capacity == front`

  rear == front가 empty와 full을 동시에 충족하므로  
  full인 경우 capacity - 1을 기준으로 삼아 관리하거나  
  size의 값을 추적하는 변수를 따로 관리해야함

### 연결 리스트

<strong>장점</strong>

- 삽입 / 삭제 성능이 좋음 - 데이터 이동이 없음  
  (배열은 원소 제거시 뒤의 원소를 한칸씩 땡겨야함)
- 확장 시 리사이즈 불필요 - 노드 단위 동적 할당  
  (배열은 확장 시 더 큰 배열 생성 + 원소 복사 과정을 거침)
- 배열의 크기를 유연하게 바꿀 수 있어 데이터 개수가 예측 불가능할 때 좋음

<strong>단점</strong>

- 구현이 비교적 복잡함
- 캐시 효율 낮음 - 비연속 메모리
- 메모리 효율 낮음 - 각 노드마다 포인터(next / prev) 저장

## 활용 예

<strong>프로세스 스케줄링</strong>, <strong>윈도우 메시지 큐</strong>.

<strong>캐시/파이프라인</strong>, <strong>BFS</strong>.

## Big-O

<strong>Enqueue / Dequeue / Front</strong>: <strong>O(1)</strong> (원형 배열/연결 리스트 기준).

</details>

<details> <summary><strong>연결 리스트 (Linked List)</strong></summary>

## 정의(ADT)

노드들이 포인터(next[, prev])로 연결된 선형 자료구조.  
배열처럼 연속된 메모리 블록이 아니라, 포인터로 서로 연결되어 있음.

## 구현(DS)

- 단일(Singly): next만

- 이중(Doubly): prev/next 모두

- 원형(Circular): tail.next === head

## 대표 연산

### 삽입 (Insertion)

- 어느 위치에든 새 노드 삽입
- 앞(head)이나 뒤(tail), 노드 사이 등.

### 삭제 (Deletion)

- 특정 위치의 노드 삭제
- 최소한 pop은 필수

### 탐색/순회 (Traversal / Search)

- 특정 값 x를 가진 노드 탐색 (선형 검색)

- 순회(반복자 제공)

### 접근 (Access)

- 특정 위치 노드 값 반환

인덱스 임의 접근은 불가하므로, 특정 지점부터 하나씩 순차적으로 접근해야함

## 특징

- 인덱스 기반 접근 불가능 → 배열보다 검색이 느림

- 배열과 달리 연속 메모리 불필요 → 크기 변경에 유연

- 포인터 저장 오버헤드 발생 → 메모리 효율에 안좋음

- 캐시 친화성 낮음 (비연속 메모리로 인해 약한 지역성)

## 오류 케이스

- 잘못된 포인터 참조: 삭제된 노드 사용 시 런타임 오류

- 메모리 누수: 삭제 시 prev/next 절연(null) 처리 안 할 경우

- 경계 처리: 빈 리스트, head/tail 삭제 시 특별 처리 필요

{ value, next[, prev] }

## 단일 리스트

- 한 방향(next)만 연결 → 구현 단순, 메모리 효율적

- 역방향 탐색 불가

## 이중 리스트

- 양방향(prev/next) 연결 → 앞뒤 탐색·삭제 유리

- 불변식 유지 필요:  
  `x.next.prev === x`  
  `x.prev.next === x`

- 메모리 오버헤드 증가(prev 추가)

## 원형 리스트

- `tail.next === head`: 원형 구조

- sentinel(더미 노드) 또는 size 필드를 두어
  empty / full 상태 판별 및 경계 단순화

## 활용 예

- LRU 캐시: 해시 + 이중 리스트 조합

- 라운드 로빈 스케줄링: 원형 리스트

- 갤러리/Alt+Tab 전환: 순환적 탐색 구조

## Big-O

- 탐색: O(n)

- 삽입/삭제(노드 참조 기반): O(1)

- front/back 삽입/삭제: O(1) (head/tail 참조 유지 시)

## 배열 vs 리스트

배열: 인덱스 기반 랜덤 접근 O(1), 중간 삽입/삭제 O(n)

리스트: 중간 삽입/삭제 O(1) (참조노드 필요), 탐색 O(n)

선택 기준: “빠른 읽기” vs “삽입/삭제 빈도”

</details>

<details><summary>캐시</summary>

## 정의

원본보다 지연시간이 낮고(더 “가까운”) 빠른 계층에  
데이터의 복사본을 임시 저장해 재접근을 빠르게 하는 메커니즘.

## 키워드

- 정본이 아님(사본 또는 파생물)
- 원본 경로보다 더 빠른 접근
- 재구성 가능

## 캐시 오염

### 정의

유용한 데이터 대신 불필요한 데이터들이 캐시를 차지해 캐시 성능을 떨어뜨리는 현상.

재사용률이 높은 데이터만 캐시에 저장하도록 캐시 전략을 설정해야함

## 정책

### 빠른 조합(현업에서 자주 쓰는 세트)

API 응답 캐시: Cache-aside + TTL + LRU + singleflight + negative cache

카탈로그/상품: Read-through + 이벤트 무효화 + 버전 키 + Stale-while-revalidate

쓰기 많은 랭킹/카운터: Write-back(+주기적 flush) + TinyLFU(Admission) + 샤딩

### 접근 패턴(읽기/쓰기 전략)

- Cache-aside(=Lazy loading):  
  앱이 캐시 우선 조회  
  캐시 미스 → 원본에서 가져와 캐시에 넣고 반환.  
  단순하고 범용적, 쓰기 · 무효화를 직접 관리해야 함.

- Read-through:  
  앱은 캐시만 호출  
  캐시 미스 → 알아서 원본을 조회해 캐시를 채움.  
  캐시 / 미들웨어에 읽기 경로를 위임하고 싶을 때 적합.

- Write-through:  
  쓰기 요청을 캐시와 원본 모두에 즉시 반영.  
  일관성 관리는 쉽지만 쓰기 성능 이득은 제한적.

- Write-back(=Write-behind):  
  캐시에만 기록 후, 원본은 배치/비동기로 반영.  
  쓰기 성능↑, 장애 시 유실 방지(큐/로그/재시도) 필수.

- Write-around:  
  쓰기는 원본만 갱신, 읽을 때 필요해지면 캐시에 적재.
  일시성 · 단발성 데이터로 캐시 오염 방지.

### 만료·무효화(신선도 정책)

- TTL/Absolute Expiration:  
  저장 시점 기준 고정 만료시간 설정.  
  업데이트 빈도가 낮거나, 약간의 오래된(stale) 값이 허용될 때 사용.

- Sliding Expiration:  
  접근할 때마다 만료시간 연장.  
   자주 쓰는 항목을 오래 유지하고 싶을 때 사용.

- Explicit Invalidation:  
  이벤트 발생 시 지정 키(키/프리픽스/태그)를 즉시 무효화.
  상품가격/게시글 수정 등 변경 즉시 반영해야 할 때 사용.

- Revalidation(검증 후 재사용):  
  원본 변경 여부에 따라 캐시 갱신을 결정.
  원본 부하/전송 비용을 최소화하며 신선도 보장.

- Stale-while-revalidate / Stale-on-error:  
  오래된(stale) 값을 즉시 반환.  
  백그라운드에서 새로고침 / 원본 장애 시 낡은 값 임시 허용.  
  사용자 지연 최소화 + 안정성 향상.

### 교체(Eviction) 정책

- LRU:  
  가장 오래 쓰이지 않은 항목부터 제거.  
  시간 지역성에 강함.

- LFU / TinyLFU:  
  사용 빈도가 낮은 항목 제거.  
  핫 키가 뚜렷하고, 대형 일회성 응답 많은 환경에 적합.

- FIFO / CLOCK / SLRU / ARC:  
  메모리·패턴·구현 난이도에 따라 대안 선택.

### 적재·사전채움(Admission/Prefetch)

- Admission(입장 규칙):  
  크기·비용·빈도 기준으로 캐싱 여부를 결정.  
  한 번 쓰고 버리는 대형 응답으로 인한 캐시 오염 방지.

- Prefetch/Pre-warm:  
  배포/스파이크 전 선적재, 시퀀스 다음 페이지 미리 채움.
  콜드스타트·초기 지연 완화.

- Negative Caching:  
  “존재하지 않음/404/빈 결과”를 짧게 캐시.
  불필요한 원본 조회 폭주 방지.

### 일관성·동기화(Consistency/Cohere­ncy)

- Write-through / Read-your-writes 보장: 같은 클라이언트가 바로 쓴 값을 곧바로 읽게.

- Event-driven Invalidation: DB 변경 이벤트→캐시 무효화(메시지 버스/PubSub).

- 버전 키/해시 키: product:{id}:v{version} 처럼 키에 버전을 포함.
  정확성↑, 키 회전으로 안전한 롤아웃.

### 다층·분산 설계

- L1/L2 캐시: 프로세스 내(in-memory) → 분산 캐시(Redis/Memcached) → CDN/프록시.
  핫 데이터는 가까운 곳(L1)에서 초저지연, L2로 공유률↑.

- 샤딩/Consistent Hashing: 키 분산으로 확장성·평형 유지.

- 복제(Replication): 가용성↑, 읽기 스케일링. 정합성 규칙을 명확히.

7. 폭주·장애 대응

- Stampede 방지: 단일 비행(singleflight)/뮤텍스로 동일 키 동시 재생성 차단.

- Jittered TTL / Probabilistic Early Expiration: 만료 시점 분산.

- Circuit Breaker / Backoff: 원본 장애 시 연쇄 실패 차단, 점진적 복구.
</details>

<details><summary>알고리즘과 시간 복잡도</summary>

## 정의

- 알고리즘 분석: 알고리즘이 소모하는 자원(시간·메모리)을 분석하는 것

- 시간 복잡도: 속도 관점
- 공간 복잡도: 메모리 사용량 관점

알고리즘을 시간과 공간의 관점에서 분석하며  
일반적으로 시간에 초점을 두어 평가함.

실행시간은 실행환경에 따라 달라지므로, 연산 횟수 증가율을 기준으로 분석함.

점근적 표기법을 사용하여 입력 크기(n)가 커질 때의 증가율을 표현

## 점근적 표기법

실행 시간이나 메모리 사용량을 T(n)으로 두고(입력 크기
n에 대한 함수),  
n→∞일 때의 증가율을 Big-O, Ω, Θ로 표현.

### 종류

### 2) 세 가지 점근적 표기법

- Big-O (O) — 상한 (최악/증가율 최대치)
  최악의 경우, 가장 느린 경우를 의미  
  예: 삽입 정렬은 O(n²) = 가장 느린 경우에 n²

- Big-Ω (Ω) — 하한 (최소 보장)
  최선의 경우, 가장 빠른 경우를 의미  
  예: 삽입 정렬은 Ω(n) = 가장 빠를 경우에 n

- Big-Θ (Θ) — 상하한 동일
  최선과 최악이 같아, 실제 성능이 일정한 경우
  예: 이분 탐색은 Θ(log n) = 성능이 일정함

- 그외에도 Little-o, Little-ω 등이 있음

## 주요 복잡도

### O(1) — 상수 시간

- 입력 크기 `n`과 무관하게 일정한 수행 시간
- 예시: 배열 인덱스로 접근 `arr[i]`
- 그래프: 평평한 선

### O(log n) — 로그 시간

- 입력 크기를 절반씩 줄이는 과정
- 예시: 이분 탐색, 균형 이진트리 탐색
- 특징: `n`이 2배 → 연산 횟수는 1 증가

### O(n) — 선형 시간

- 입력 크기에 비례
- 예시: 배열 전체 순회, 선형 탐색
- 특징: 입력 2배 → 수행 시간도 2배

### O(n log n) — 로그-선형 시간

- 선형 반복 + 로그 단계 결합
- 예시: 퀵/머지/힙 정렬
- 특징: `O(n²)`보다는 훨씬 작음

### O(n²) — 이차 시간

- 중첩 반복문에서 발생
- 예시: 버블 정렬, 삽입 정렬, 플로이드-워셜
- 특징: `n=1000 → 1,000,000 연산`

### O(2^n) — 지수 시간

- 입력 1 증가 → 연산량 2배
- 예시: 부분집합 탐색, 피보나치 재귀
- 특징: `n=30` → 수억 단위 연산

### O(n!) — 팩토리얼 시간

- 가능한 모든 순서 탐색
- 예시: 외판원 문제 완전탐색, 순열 생성
- 특징: `n=20` → 2.4조 연산

### 그 외

- **O(√n)**: 약수 찾기
- **O(log log n)**: 로그를 반복 적용하는 경우
- **O(α(n))**: inverse Ackermann 함수, 거의 상수

## 분할상환(Armortized) 복잡도

- 알고리즘의 여러 연산을 묶어 평균화 하는 분석 기법.
- 알고리즘의 성능에 영향을 미치는 다른 요인들을 전부 고려함.
- 각 연산의 평균 수행성능을 보장함.

## 보완/추가 개념

### 실제 체감 차이

- 작은 입력에서는 O(n²) 정렬이 더 빠를 수 있음 (상수항·구현 단순성)
- 실무에서는 하이브리드 정렬 사용 (팀소트, 인트로소트)

</details>

<details><summary> 분기 예측이란?</summary>

## 분기 예측이란?

CPU는 파이프라인 방식으로 “앞으로 실행할 명령어”를 미리 가져와서 준비함.  
if (a > b) 같은 조건문(분기)이 나오면, 결과를 모른 채로 실행해야 함.

그래서 CPU가 결과를 예상하여 명령어를 미리 준비함.

예상이 맞으면 그대로 진행하지만, 예상이 틀리면 준비한 명령어들을 버리고 다시 로드해야함.  
→ 큰 성능 손해가 발생

## 대안

- 조건문 없는 스왑 기법 (branchless swap):  
  조건문을 연산으로 대체해, 항상 같은 실행 경로를 밟게 만드는 방법.

- 정렬 네트워크(sorting network):  
  분기 대신 고정된 비교·교환 패턴으로 동작

- 데이터 정렬 전처리:  
  입력이 거의 정렬돼 있다면 분기 예측 성공률이 높아짐.

</details>

<details><summary>정렬</summary>
<details><summary>버블 정렬 (Bubble Sort)</summary>

## 요약

- 원리: 인접한 두 원소를 비교하여 스왑

- 특징: 비교 기반, 안정적, 제자리, 구현 단순

- 복잡도: 평균/최악 O(n²), 최선 O(n)(조기 종료)

- 활용도: 다른 정렬 사용 추천

## 원리

인접한 두 원소를 비교하여 순서가 잘못되면 스왑하는 비교 기반 정렬

한 번의 패스(전체 순회)가 끝나면 가장 큰 값이 맨 뒤에 고정됨(오름차순 기준)

## 시간·공간·속성

- 시간 복잡도:  
  평균/최악 O(n²), 최선 O(n)(조기 종료 적용 시)

- 공간 복잡도:  
  O(1) (제자리 정렬, in-place)

- 안정성: 안정적(동일 값의 상대 순서 보존)

- 실행 특성: 스왑 횟수가 많아 실제 체감 속도가 느린 편

## 활용처

- 개념 학습: 비교·스왑·패스 개념 설명에 적합

- 거의 정렬된 데이터: 조기 종료가 자주 발생하는 경우

- 작은 입력: 원소 수가 매우 작을 때 간단 구현/시연용

## 한계

- 스왑 비용이 큰 환경에서 특히 비효율적 (데이터 단위의 크기가 큰 경우)

- 입력이 조금만 커져도 O(n²)로 급격히 느려짐 (실 사용 X)

- 동일 난이도라면 삽입 정렬또는 선택 정렬이 더 실용적임

포인터만 변경하는 링크드 리스트의 경우, 스왑 비용은 적지만  
요소에 접근하기 위해 순회하는 비용이 커져서 여전히 비효율적임

## 최적화 로직

- 조기 종료(Early Stopping)
  한 패스 동안 스왑이 없으면 즉시 종료  
  → 최선 O(n) 가능

- 비교 범위 축소(lastSwap 기법)  
  마지막으로 스왑된 위치 이후는 정렬 완료  
  다음 패스에서 해당 인덱스까지만 비교

- 꼬리 구간 생략(고정된 뒤쪽 무시)  
  패스 종료 시 마지막 원소의 위치가 확정되므로,  
  비교 범위를 1씩 줄이는 고정 규칙 적용.

- Cocktail Shaker, Comb, Odd-Even 등 변형이 있음

## 비용 모델(메모리·캐시·분기)

- 메모리: 버블은 스왑 중심 → 쓰기 연산량 많음(스왑당 3회 대입)

- 캐시: 선형 스캔(연속된 인접 원소만 접근)이라 비교 지역성은 좋음

- 분기 예측: 비교-스왑 분기(조건문)가 많아 예측 실패 비용이 누적됨

</details>

<details><summary>선택 정렬 (Selection Sort)</summary>

## 요약

- 원리: 최솟값을 선택해 현재 위치(i)와 스왑

- 복잡도: 비교는 항상 O(n²), 스왑은 최대 n-1

- 성질: 제자리, 불안정, 구현 단순

- 활용도: 쓰기 비용이 매우 큰 환경에서 고려할만함

## 원리

현재 위치 i에서 이후 구간의 최솟값을 찾아  
i와 교환하는 과정을 반복하는 비교 기반 정렬.  
(i = 0 → n-1까지)

한 번의 패스가 끝나면 가장 작은 값이 앞쪽으로 확정됨(오름차순 기준).

## 시간·공간·속성

- 시간 복잡도:
  비교 횟수 ≈ n(n-1)/2 → 최선/평균/최악 모두 O(n²)
  스왑 횟수 ≤ n-1(한 패스에 최대 1회)

- 공간 복잡도:
  O(1) (제자리 정렬, in-place)

- 안정성:
  불안정 정렬(동일 값의 상대 순서가 깨질 수 있음)

## 실행 특성:

비교는 많고, 쓰기(스왑)가 적음 → “쓰기 비용이 비싼 환경”에 적합

## 활용처

- 쓰기 비용이 큰 경우: 데이터 단위가 커 복사 비용이 큰 경우  
  (그래도 n log n 정렬보다는 안좋음)

- 작은 입력: 원소 수가 매우 적은 경우

- 개념 학습: 선택·교환 개념 설명에 용이

## 한계

- 거의 정렬된 경우에도 비교가 줄지 않음

- 대규모 데이터 비적합: O(n log n) 계열(퀵/머지/힙) 대비 현저히 느림

연결 리스트에 적용하면 포인터만 바꿔 스왑 비용은 적지만,  
매 패스마다 최솟값 탐색 순회가 필요해 여전히 O(n²)

## 최적화 로직

- 양방향 선택 정렬(Double Selection):  
  한 패스에서 최솟값과 최댓값을 동시에 찾아 양 끝에 배치  
  → 패스 수는 줄지만 복잡도는 여전히 O(n²)

- 불필요한 스왑 최소화:  
  찾은 최솟값이 이미 제자리면 스왑 생략 → 쓰기 횟수 감소(여전히 ≤ n-1)

- 힙 정렬(Heap Sort)로 확장:  
  선택 과정을 힙(Heap) 자료구조로 구현 → O(log n)

## 비용 모델(메모리·캐시·분기)

- 메모리: 패스당 0~1회 스왑 → 총 스왑 횟수는 n-1 이하

- 캐시:  
  최솟값 탐색이 선형 스캔 중심이므로 공간 지역성이 좋음

- 분기 예측:  
  '현재 최솟값 갱신 여부' 분기가 반복되나, 스왑 분기 빈도는 낮음

</details>

<details><summary>삽입 정렬 (Insertion Sort)</summary>

## 요약

- 원리:  
  배열을 왼쪽(정렬)과 오른쪽(미정렬)으로 나눈 후,  
  오른쪽(미정렬)에서 뽑아, 왼쪽(정렬)의 알맞은 위치에 삽입.

- 복잡도: 평균/최악 O(n²), 최선 O(n)

- 성질: 안정적, 제자리, 작은 입력/거의 정렬된 데이터에 적합

- 활용도: 단독 주력보단 소규모 구간/보조 루틴으로 사용

## 정의

배열을 “정렬된 부분”과 “미정렬 부분”으로 나누고, 미정렬 부분에서 원소를 하나씩 꺼내어  
정렬된 부분의 알맞은 위치에 삽입하여 전체를 정렬하는 알고리즘

## 원리

1. 배열을 두 부분으로 나눔

   - 왼쪽: 이미 정렬된 부분
   - 오른쪽: 아직 정렬되지 않은 부분

2. 미정렬 구간의 첫 원소(i 번째)를 current로 설정

3. 정렬된 부분의 오른쪽 끝( j = i-1 )부터 역방향으로 탐색

4. j > current 일 경우 array[i] = array[j]로 덮어쓴 후 다음 인덱스로 이동( j-- )

5. 4번을 반복하다 올바른 위치에 current 값 삽입.

6. 이 과정을 i = 1 → n-1까지 반복.

덮어쓰면서 이동하기 때문에 기존 원소를 밀어내는 것처럼 표현됨

버블 정렬, 선택정렬과는 다른 덮어쓰기 방식으로 진행됨.

- 1회 이동 = array[j+1] = array[j] = 대입 1회
- 1회 삽입 = array[j+1] = current = 대입 1회

- 불변식: [0..i) 구간은 항상 정렬됨

<details><summary> 구간 표기법</summary>

## 구간 표기법

대괄호 [ 또는 ] → 해당 끝점을 포함한다(inclusive)

소괄호 ( 또는 ) → 해당 끝점을 포함하지 않는다(exclusive)

## [0..i)의 의미

- 0은 포함됨 → 구간 시작점 포함 (0번째 원소는 정렬된 집합에 포함)

- i는 포함되지 않음 → 구간 끝점 제외 (i번째 원소는 아직 정렬 구간에 포함되지 않음)

- “0번 인덱스부터 i-1번 인덱스까지는 항상 정렬돼 있다”

</details>

## 시간·공간·속성

- 시간 복잡도:

  - 최악(역순 배열): 각 원소가 끝까지 밀리므로 총 대입 ≈ n(n-1)/2 + n ≈ O(n²)
  - 최선(이미 정렬): 각 단계에서 삽입만 1회 → 총 대입 ≈ n

- 공간 복잡도: O(1) (제자리 정렬, in-place)

- 안정성: 안정적(동일 키의 상대 순서 보존)  
  구현 시 > 비교만 사용(동일 값 원소의 상대적 순서 유지)

- 실행 특성: 이동(shift) 중심이라 인접 메모리 쓰기 → 캐시 친화적

- 작은 입력·거의 정렬된 데이터에서 체감 성능이 좋음

## 활용처

- 작은 데이터셋: 상수항이 작아 실사용에서도 빠르게 동작

- 거의 정렬된 데이터: 최선 O(n)에 근접

- 하이브리드 정렬 보조 루틴: 퀵/머지/팀소트 등에서 작은 입력 처리

## 한계

- 무작위·역순 데이터에서는 이동이 많아 성능이 안좋음(O(n²))

- 대규모 데이터에서 O(n log n) 계열보다 성능이 안좋음

- 연결 리스트: 삽입 자체는 O(1) 이지만, 위치 찾기 순회가 필요함 (전체 O(n²))

## 최적화 방법

- 조기 종료:  
  왼쪽 탐색 중 현재 원소 ≤ 키를 만나면 즉시 중단 → 이미 그 앞은 모두 ≤ 키  
  이미 정렬된 배열에서 비교 n-1회, 이동 0회 → O(n)

- 이진 탐색 삽입(Binary Insertion Sort):  
  삽입 위치 탐색을 이진 탐색(O(log n))으로 수행  
  → 비교 횟수 감소, 전체는 여전히 O(n²)

  비교가 비싼 환경(복잡한 키 비교)에서 유의미

- 셸 정렬(Shell Sort)로 확장:  
   멀리 떨어진 원소 정렬시 많은 이동이 필요하다는 기존의 단점을 보완.  
   \
   간격(gap) 을 두고 떨어진 원소들끼리 먼저 부분 정렬한 뒤,  
   점점 간격을 줄여가면서 전체를 정렬하는 알고리즘  
   → O(n^(3/2)) ~ O(n log² n) 수준까지 개선 가능 (최악은 구현/시퀀스에 따라 O(n²))

- 센티넬(Sentinel) 기법:
  배열 맨 앞에 "절대 최소값"을 넣어두고,  
  반복문에서 경계 검사(j >= 0)를 없애는 방식.  
  → index 검사를 기존 비교 조건으로도 수행할 수 있도록 만드는 트릭

## 비용 모델(메모리·캐시·분기)

- 메모리: 연속 이동(shift) → 스왑 대비 쓰기 패턴이 효율적

- 캐시: 왼쪽으로 연속 접근하므로 공간 지역성↑

- 분기 예측: 크기 비교 단일 분기 반복 → 정렬될수록 예측 성공률↑

</details>

<details><summary>병합 정렬 (Merge Sort)</summary>

## 요약

- 원리 : 분할(반씩 쪼갬) → 정복(각자 정렬) → 병합(두 정렬된 리스트를 합침)

- 시간 복잡도: 항상 Θ(n log n) (최선/평균/최악 동일)

- 공간 복잡도:

  - 배열:  
    버퍼 - Θ(n), 스택 - 재귀 O(log n) / 총 - O(n)
  - 연결 리스트:  
    버퍼 - O(1), 스택 - 재귀 O(log n) / 반복 O(1), 총 - 최대 O(1)

- 안정성: 안정 정렬(동일 키의 상대 순서 보존; 동등비교 시 왼쪽 우선 선택)

- 활용: 대용량/안정성 요구 환경, 외부 정렬(디스크), 하이브리드 정렬

함수 호출 스택이란?

## 원리(분할·정복)

lo: 구간의 시작 인덱스 (low)  
hi: 구간의 끝 인덱스 (high)  
mid: 구간의 가운데 인덱스 (middle)

### 분할(Divide)

배열을 왼쪽 A[lo..mid], 오른쪽 A[mid+1..hi] 와 같이 분할

분할 자체는 인덱스 연산 → O(1)

### 정복(Conquer)

두 하위 배열에 동일한 분할 알고리즘을 재귀/반복 적용

길이가 0 또는 1이면 (기저조건) 이미 정렬되었다고 간주 후 재귀 종료.

### 병합(Merge)

정렬된 두 구간을 두 포인터로 한 번 훑으며 합침

한쪽이 소진되면 나머지 전부 복사

### 병합의 불변식

결과 배열의 접두사(prefix)는 항상 정렬됨

다음 후보는 왼쪽 i, 오른쪽 j의 최소값 중 하나

동등 비교 시 왼쪽을 먼저 택하면 안정성 보장

시간 분석 직관

병합은 각 원소를 정확히 한 번 출력 → Θ(n)

재귀 트리 깊이 log₂ n, 각 레벨에서 총 작업량 n → n log n

## 시간·공간·속성

- 시간: 최선/평균/최악 Θ(n log n) → 성능이 일정함

- 공간:

  - 배열: 버퍼 Θ(n), 재귀 스택 O(log n),
    Bottom-up(반복) + 공유 보조배열(aux) 로 스택 제거 가능

  - 연결 리스트: 버퍼(포인터 재연결) O(1)

- 안정성: 안정적

- 적응성: 기본형은 비적응적, “런(run) 감지”로 보완 가능

## 활용처

- 안정성이 필요한 대규모 정렬

- 외부 정렬(External Sort): 메모리에 안 들어오는 초대용량(로그, 트랜잭션)

- 연결 리스트 정렬: 포인터 재배치만으로 효율적

- 하이브리드 정렬: 팀소트(Timsort) 등에서 런 감지 + 병합

## 최적화

- 작은 구간 삽입 정렬(Threshold): 작은 구간은 삽입 정렬로 처리 → 상수항 절감

- 이미 정렬이면 병합 생략: left.last ≤ right.first면 O(n) 병합 생략

- 보조배열 재사용: 호출마다 새 배열 대신 공유 aux 사용 → 할당/복사 비용 감소

- Bottom-up(반복형): run 크기 1,2,4,8…로 키워가며 인접 블록 병합 → 스택 오버헤드 0, 캐시 친화 개선

- 자연 병합(Natural Mergesort): 입력에서 증가/감소 런을 감지해 바로 병합 → 실효 성능↑(팀소트의 핵심)

- 연결 리스트 분할/병합: slow/fast로 중앙 분할, 포인터만 재연결해 안정 병합

- 외부 정렬 최적화: k-way merge(힙) 로 I/O 최소화, replacement selection으로 더 긴 run 생성

- 병렬화: 좌/우 분할을 병렬 처리, 병합도 분할 병합으로 병렬화(워크 스틸링 등)

- 센티넬 사용: 경계 체크 분기 제거(저수준 언어에서 유용)

## 비용 모델(메모리·캐시·분기)

- 메모리: 배열은 버퍼 왕복 복사가 필요 → 쓰기량 큼(보조배열 재사용으로 완화)

- 캐시: 병합은 선형 스트리밍 읽기/쓰기 → 캐시/디스크 접근 패턴에 유리

- 분기 예측: 두 포인터 비교 분기 반복. 런 감지/병합 생략으로 분기 수 자체를 줄일 수 있음

</details>
</details>
