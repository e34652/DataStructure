<strong>ADT (Abstract Data Type)</strong>: “무엇을 할 수 있는가”를 정의하는 <strong>행동 규약</strong> (예시: <strong>스택</strong> = LIFO, <strong>큐</strong> = FIFO).

<strong>DS (Data Structure)</strong>: 그 규약을 만족하도록 실제로 <strong>저장·연결·탐색</strong>하는 <strong>구현 방식</strong> (예시: <strong>배열</strong>, <strong>연결 리스트</strong>, <strong>원형 버퍼</strong> 등).

<strong>예</strong>: <strong>모델링(ADT)</strong>은 스택, <strong>구현(DS)</strong>은 “배열로 만든 스택”, “연결 리스트로 만든 스택” 등 다양하게 가능.

<details> <summary><strong>스택 (Stack)</strong></summary>

## 정의(ADT)

- <strong>LIFO(후입선출)</strong> 규칙을 가지는 선형 자료구조.

- 한쪽 끝에서만 삽입/삭제가 일어남.

- 최근 원소를 가리키는 멤버 top을 가짐(필드).

## 특징

- 입력·삭제 모두 <strong>한 방향</strong>에서 수행.

- <strong>pop( )</strong> 후 <strong>top</strong>은 <strong>그 직전 원소</strong>를 가리킴.

- <strong>배열/연결 리스트</strong> 등 여러 DS로 구현 가능.

## 대표 연산(메서드)

- `push(x)`: 맨 위에 삽입
- `pop()`: 맨 위 원소 제거+반환  
  ( 요소를 꺼내며 제거하는 연산, 자료구조마다 위치는 다름)

- `top()/peek()`: 맨 위 원소 조회
- `empty()`: 자료구조가 비어 있는지 확인
- `size()`: 자료구조에 들어 있는 요소의 개수를 반환

## 오류 케이스

- <strong>Underflow</strong>: 빈 스택에서 <code>pop</code>/<code>top</code>.

- <strong>Overflow</strong>: 고정 용량에서 한도를 초과한 <code>push</code>.

## 구현방식

- <strong>동적 배열</strong>: 캐시 친화적

- <strong>연결 리스트</strong>: 중간 조작 유리

## <strong>캐시 친화적인 이유</strong>:

CPU는 읽을 때 인접 메모리 블록까지 <strong>프리패치</strong>해 연속 접근이 빠름.

따라서 메모리 상에서 연속된 공간을 차지하는 동적 배열은  
지역성이 캐시 효율이 더 좋음

## 활용 예시

- 브라우저 <strong>뒤로가기</strong>
- <strong>실행 취소(Undo)</strong>
- <strong>후위 표기식 계산</strong>
- <strong>호출 스택</strong>

## Big-O

<strong>Push / Pop / Top</strong>: 평균 <strong>O(1)</strong>.

</details>
<details> <summary><strong>큐 (Queue)</strong></summary>

## 정의(ADT)

- <strong>FIFO(선입선출)</strong> 규칙을 가지는 선형 자료구조.

- 뒤(<strong>rear</strong>)로 삽입, 앞(<strong>front</strong>)에서 삭제 — <strong>입·출력 위치 분리</strong>.

## 특징

- <strong>front</strong>: 삭제/조회가 일어나는 위치(맨 앞).

- <strong>rear</strong>: 삽입이 일어나는 위치(맨 뒤).

- 먼저 들어온 데이터가 먼저 나가는 <strong>대기 행렬</strong>.

- <strong>배열 / 연결 리스트</strong> 등 여러 DS로 구현 가능.

## 대표 연산(메서드)

- <strong>`enqueue(x)`</strong>: 뒤(<strong>rear/back</strong>)에 삽입.

- <strong>`dequeue()`</strong>: 앞(<strong>front</strong>)에서 제거+반환.

- <strong>`front()` / `peek()`</strong>: 가장 앞 요소 조회(보존).

- <strong>`empty()`</strong>: 공백 여부

- <strong>`size()`</strong>()요소 수 확인.

## 오류 케이스

- <strong>Underflow</strong>: 빈 큐에서 <code>dequeue</code>.

- <strong>Overflow</strong>: 고정 용량에서 한도를 초과한 <code>enqueue</code>.

## 구현방식

### 단순 배열

- 구현이 간단함
- 인덱스가 정적으로 관리되어 인덱스 활용이 제한적  
  (front와 rear가 오직 증가만 하기 때문에 `dequeue` 연산으로 제거된 인덱스 재사용 불가)

  → <strong>원형 큐</strong>로 보완해 빈 칸을 재활용.

### 원형 큐

- rear와 front를 모듈러 연산(%, mod)으로 관리하여  
  인덱스가 순환하는 구조의 큐

- 인덱스 갱신:  
  rear = `(rear + 1) % capacity`  
  front = `(front + 1) % capacity`

- 크기 계산(현재 원소 개수):  
  size = `(rear - front + capacity) % capacity`

- isEmpty:  
  `size == 0`  
  `rear == front`

- isFull:  
  `size == capacity - 1`  
  `(rear+1) % capacity == front`

  rear == front가 empty와 full을 동시에 충족하므로  
  full인 경우 capacity - 1을 기준으로 삼아 관리하거나  
  size의 값을 추적하는 변수를 따로 관리해야함

### 연결 리스트

<strong>장점</strong>

- 삽입 / 삭제 성능이 좋음 - 데이터 이동이 없음  
  (배열은 원소 제거시 뒤의 원소를 한칸씩 땡겨야함)
- 확장 시 리사이즈 불필요 - 노드 단위 동적 할당  
  (배열은 확장 시 더 큰 배열 생성 + 원소 복사 과정을 거침)
- 배열의 크기를 유연하게 바꿀 수 있어 데이터 개수가 예측 불가능할 때 좋음

<strong>단점</strong>

- 구현이 비교적 복잡함
- 캐시 효율 낮음 - 비연속 메모리
- 메모리 효율 낮음 - 각 노드마다 포인터(next / prev) 저장

## 활용 예

<strong>프로세스 스케줄링</strong>, <strong>윈도우 메시지 큐</strong>.

<strong>캐시/파이프라인</strong>, <strong>BFS</strong>.

## Big-O

<strong>Enqueue / Dequeue / Front</strong>: <strong>O(1)</strong> (원형 배열/연결 리스트 기준).

</details>

<details> <summary><strong>연결 리스트 (Linked List)</strong></summary>

## 정의(ADT)

노드들이 포인터(next[, prev])로 연결된 선형 자료구조.  
배열처럼 연속된 메모리 블록이 아니라, 포인터로 서로 연결되어 있음.

## 구현(DS)

- 단일(Singly): next만

- 이중(Doubly): prev/next 모두

- 원형(Circular): tail.next === head

## 대표 연산

### 삽입 (Insertion)

- 어느 위치에든 새 노드 삽입
- 앞(head)이나 뒤(tail), 노드 사이 등.

### 삭제 (Deletion)

- 특정 위치의 노드 삭제
- 최소한 pop은 필수

### 탐색/순회 (Traversal / Search)

- 특정 값 x를 가진 노드 탐색 (선형 검색)

- 순회(반복자 제공)

### 접근 (Access)

- 특정 위치 노드 값 반환

인덱스 임의 접근은 불가하므로, 특정 지점부터 하나씩 순차적으로 접근해야함

## 특징

- 인덱스 기반 접근 불가능 → 배열보다 검색이 느림

- 배열과 달리 연속 메모리 불필요 → 크기 변경에 유연

- 포인터 저장 오버헤드 발생 → 메모리 효율에 안좋음

- 캐시 친화성 낮음 (비연속 메모리로 인해 약한 지역성)

## 오류 케이스

- 잘못된 포인터 참조: 삭제된 노드 사용 시 런타임 오류

- 메모리 누수: 삭제 시 prev/next 절연(null) 처리 안 할 경우

- 경계 처리: 빈 리스트, head/tail 삭제 시 특별 처리 필요

{ value, next[, prev] }

## 단일 리스트

- 한 방향(next)만 연결 → 구현 단순, 메모리 효율적

- 역방향 탐색 불가

## 이중 리스트

- 양방향(prev/next) 연결 → 앞뒤 탐색·삭제 유리

- 불변식 유지 필요:  
  `x.next.prev === x`  
  `x.prev.next === x`

- 메모리 오버헤드 증가(prev 추가)

## 원형 리스트

- `tail.next === head`: 원형 구조

- sentinel(더미 노드) 또는 size 필드를 두어
  empty / full 상태 판별 및 경계 단순화

## 활용 예

- LRU 캐시: 해시 + 이중 리스트 조합

- 라운드 로빈 스케줄링: 원형 리스트

- 갤러리/Alt+Tab 전환: 순환적 탐색 구조

## Big-O

- 탐색: O(n)

- 삽입/삭제(노드 참조 기반): O(1)

- front/back 삽입/삭제: O(1) (head/tail 참조 유지 시)

## 배열 vs 리스트

배열: 인덱스 기반 랜덤 접근 O(1), 중간 삽입/삭제 O(n)

리스트: 중간 삽입/삭제 O(1) (참조노드 필요), 탐색 O(n)

선택 기준: “빠른 읽기” vs “삽입/삭제 빈도”

</details>

<details><summary>캐시</summary>

## 정의

원본보다 지연시간이 낮고(더 “가까운”) 빠른 계층에  
데이터의 복사본을 임시 저장해 재접근을 빠르게 하는 메커니즘.

## 키워드

- 정본이 아님(사본 또는 파생물)
- 원본 경로보다 더 빠른 접근
- 재구성 가능

## 캐시 오염

### 정의

유용한 데이터 대신 불필요한 데이터들이 캐시를 차지해 캐시 성능을 떨어뜨리는 현상.

재사용률이 높은 데이터만 캐시에 저장하도록 캐시 전략을 설정해야함

## 정책

### 빠른 조합(현업에서 자주 쓰는 세트)

API 응답 캐시: Cache-aside + TTL + LRU + singleflight + negative cache

카탈로그/상품: Read-through + 이벤트 무효화 + 버전 키 + Stale-while-revalidate

쓰기 많은 랭킹/카운터: Write-back(+주기적 flush) + TinyLFU(Admission) + 샤딩

### 접근 패턴(읽기/쓰기 전략)

- Cache-aside(=Lazy loading):  
  앱이 캐시 우선 조회  
  캐시 미스 → 원본에서 가져와 캐시에 넣고 반환.  
  단순하고 범용적, 쓰기 · 무효화를 직접 관리해야 함.

- Read-through:  
  앱은 캐시만 호출  
  캐시 미스 → 알아서 원본을 조회해 캐시를 채움.  
  캐시 / 미들웨어에 읽기 경로를 위임하고 싶을 때 적합.

- Write-through:  
  쓰기 요청을 캐시와 원본 모두에 즉시 반영.  
  일관성 관리는 쉽지만 쓰기 성능 이득은 제한적.

- Write-back(=Write-behind):  
  캐시에만 기록 후, 원본은 배치/비동기로 반영.  
  쓰기 성능↑, 장애 시 유실 방지(큐/로그/재시도) 필수.

- Write-around:  
  쓰기는 원본만 갱신, 읽을 때 필요해지면 캐시에 적재.
  일시성 · 단발성 데이터로 캐시 오염 방지.

### 만료·무효화(신선도 정책)

- TTL/Absolute Expiration:  
  저장 시점 기준 고정 만료시간 설정.  
  업데이트 빈도가 낮거나, 약간의 오래된(stale) 값이 허용될 때 사용.

- Sliding Expiration:  
  접근할 때마다 만료시간 연장.  
   자주 쓰는 항목을 오래 유지하고 싶을 때 사용.

- Explicit Invalidation:  
  이벤트 발생 시 지정 키(키/프리픽스/태그)를 즉시 무효화.
  상품가격/게시글 수정 등 변경 즉시 반영해야 할 때 사용.

- Revalidation(검증 후 재사용):  
  원본 변경 여부에 따라 캐시 갱신을 결정.
  원본 부하/전송 비용을 최소화하며 신선도 보장.

- Stale-while-revalidate / Stale-on-error:  
  오래된(stale) 값을 즉시 반환.  
  백그라운드에서 새로고침 / 원본 장애 시 낡은 값 임시 허용.  
  사용자 지연 최소화 + 안정성 향상.

### 교체(Eviction) 정책

- LRU:  
  가장 오래 쓰이지 않은 항목부터 제거.  
  시간 지역성에 강함.

- LFU / TinyLFU:  
  사용 빈도가 낮은 항목 제거.  
  핫 키가 뚜렷하고, 대형 일회성 응답 많은 환경에 적합.

- FIFO / CLOCK / SLRU / ARC:  
  메모리·패턴·구현 난이도에 따라 대안 선택.

### 적재·사전채움(Admission/Prefetch)

- Admission(입장 규칙):  
  크기·비용·빈도 기준으로 캐싱 여부를 결정.  
  한 번 쓰고 버리는 대형 응답으로 인한 캐시 오염 방지.

- Prefetch/Pre-warm:  
  배포/스파이크 전 선적재, 시퀀스 다음 페이지 미리 채움.
  콜드스타트·초기 지연 완화.

- Negative Caching:  
  “존재하지 않음/404/빈 결과”를 짧게 캐시.
  불필요한 원본 조회 폭주 방지.

### 일관성·동기화(Consistency/Cohere­ncy)

- Write-through / Read-your-writes 보장: 같은 클라이언트가 바로 쓴 값을 곧바로 읽게.

- Event-driven Invalidation: DB 변경 이벤트→캐시 무효화(메시지 버스/PubSub).

- 버전 키/해시 키: product:{id}:v{version} 처럼 키에 버전을 포함.
  정확성↑, 키 회전으로 안전한 롤아웃.

### 다층·분산 설계

- L1/L2 캐시: 프로세스 내(in-memory) → 분산 캐시(Redis/Memcached) → CDN/프록시.
  핫 데이터는 가까운 곳(L1)에서 초저지연, L2로 공유률↑.

- 샤딩/Consistent Hashing: 키 분산으로 확장성·평형 유지.

- 복제(Replication): 가용성↑, 읽기 스케일링. 정합성 규칙을 명확히.

7. 폭주·장애 대응

- Stampede 방지: 단일 비행(singleflight)/뮤텍스로 동일 키 동시 재생성 차단.

- Jittered TTL / Probabilistic Early Expiration: 만료 시점 분산.

- Circuit Breaker / Backoff: 원본 장애 시 연쇄 실패 차단, 점진적 복구.
</details>

<details><summary>알고리즘과 시간 복잡도</summary>

## 정의

- 알고리즘 분석: 알고리즘이 소모하는 자원(시간·메모리)을 분석하는 것

- 시간 복잡도: 속도 관점
- 공간 복잡도: 메모리 사용량 관점

알고리즘을 시간과 공간의 관점에서 분석하며  
일반적으로 시간에 초점을 두어 평가함.

실행시간은 실행환경에 따라 달라지므로, 연산 횟수 증가율을 기준으로 분석함.

점근적 표기법을 사용하여 입력 크기(n)가 커질 때의 증가율을 표현

## 점근적 표기법

실행 시간이나 메모리 사용량을 T(n)으로 두고(입력 크기
n에 대한 함수),  
n→∞일 때의 증가율을 Big-O, Ω, Θ로 표현.

### 종류

### 2) 세 가지 점근적 표기법

- Big-O (O) — 상한 (최악/증가율 최대치)
  최악의 경우, 가장 느린 경우를 의미  
  예시: 삽입 정렬은 O(n²) = 가장 느린 경우에 n²

- Big-Ω (Ω) — 하한 (최소 보장)
  최선의 경우, 가장 빠른 경우를 의미  
  예시: 삽입 정렬은 Ω(n) = 가장 빠를 경우에 n

- Big-Θ (Θ) — 상하한 동일
  최선과 최악이 같아, 실제 성능이 일정한 경우
  예시: 이분 탐색은 Θ(log n) = 성능이 일정함

- 그외에도 Little-o, Little-ω 등이 있음

## 주요 복잡도

### O(1) — 상수 시간

- 입력 크기 `n`과 무관하게 일정한 수행 시간
- 예시: 배열 인덱스로 접근 `arr[i]`
- 그래프: 평평한 선

### O(log n) — 로그 시간

- 입력 크기를 절반씩 줄이는 과정
- 예시: 이분 탐색, 균형 이진트리 탐색
- 특징: `n`이 2배 → 연산 횟수는 1 증가

### O(n) — 선형 시간

- 입력 크기에 비례
- 예시: 배열 전체 순회, 선형 탐색
- 특징: 입력 2배 → 수행 시간도 2배

### O(n log n) — 로그-선형 시간

- 선형 반복 + 로그 단계 결합
- 예시: 퀵/머지/힙 정렬
- 특징: `O(n²)`보다는 훨씬 작음

### O(n²) — 이차 시간

- 중첩 반복문에서 발생
- 예시: 버블 정렬, 삽입 정렬, 플로이드-워셜
- 특징: `n=1000 → 1,000,000 연산`

### O(2^n) — 지수 시간

- 입력 1 증가 → 연산량 2배
- 예시: 부분집합 탐색, 피보나치 재귀
- 특징: `n=30` → 수억 단위 연산

### O(n!) — 팩토리얼 시간

- 가능한 모든 순서 탐색
- 예시: 외판원 문제 완전탐색, 순열 생성
- 특징: `n=20` → 2.4조 연산

### 그 외

- **O(√n)**: 약수 찾기
- **O(log log n)**: 로그를 반복 적용하는 경우
- **O(α(n))**: inverse Ackermann 함수, 거의 상수

## 분할상환(Armortized) 복잡도

- 알고리즘의 여러 연산을 묶어 평균화 하는 분석 기법.
- 알고리즘의 성능에 영향을 미치는 다른 요인들을 전부 고려함.
- 각 연산의 평균 수행성능을 보장함.

## 보완/추가 개념

### 실제 체감 차이

- 작은 입력에서는 O(n²) 정렬이 더 빠를 수 있음 (상수항·구현 단순성)
- 실무에서는 하이브리드 정렬 사용 (팀소트, 인트로소트)

</details>

<details><summary> 분기 예측이란?</summary>

## 분기 예측이란?

CPU는 파이프라인 방식으로 “앞으로 실행할 명령어”를 미리 가져와서 준비함.  
if (a > b) 같은 조건문(분기)이 나오면, 결과를 모른 채로 실행해야 함.

그래서 CPU가 결과를 예상하여 명령어를 미리 준비함.

예상이 맞으면 그대로 진행하지만, 예상이 틀리면 준비한 명령어들을 버리고 다시 로드해야함.  
→ 큰 성능 손해가 발생

## 대안

- 조건문 없는 스왑 기법 (branchless swap):  
  조건문을 연산으로 대체해, 항상 같은 실행 경로를 밟게 만드는 방법.

- 정렬 네트워크(sorting network):  
  분기 대신 고정된 비교·교환 패턴으로 동작

- 데이터 정렬 전처리:  
  입력이 거의 정렬돼 있다면 분기 예측 성공률이 높아짐.

</details>

<details><summary>정렬</summary>
<details><summary>정렬 알고리즘 분류1</summary>

## 제자리 정렬 (In-place) vs 비제자리 정렬 (Not in-place)

### 구분 기준

정렬 중 추가 보조 공간 사용량 기준

- In-place: 추가 공간이 O(1) ~ 재귀 스택 포함 O(log n)  
  예시: 삽입, 선택, 퀵(제자리 파티션), 힙

- Not in-place: 보조 배열 등 O(n) 추가 공간 활용  
  예시: 배열 기반 병합, 계수, 기수

### 활용도

- 제자리 정렬:  
  메모리 제한되는 환경

- 비제자리 정렬:  
  안정성이 필요 하거나 선형 시간 목표

### 참고

- 일부 엄격한 정의에선 O(1) 만 In-place로 인정.
- 연결 리스트 병합 정렬(반복형)의 포인터 재연결은 O(1) = in-place

## 안정 정렬 (Stable) vs 불안정 정렬 (Unstable)

### 구분 기준

정렬 후 동일 키의 상대 순서 보존 여부

- Stable: 동일 키의 상대 순서가 유지됨  
  예시: 버블, 삽입, 병합(동일 키는 ‘왼쪽 먼저’ 병합 시), Timsort 등

- Unstable: 동일 키의 상대 순서가 바뀔 수 있음  
  예시: 선택, 퀵, 힙, 셸 등

### 활용도

- 안정 정렬:  
  다중 키 정렬(2차, 3차 정렬), 동일 키의 순서 보존

- 불안정 정렬:  
  안정성 불필요, 메모리 제약, 상수항 / 캐시 이점 중시

### 참고

- 불안정 알고리즘도 보조수단을 통한 안정화 시,  
  안정 알고리즘으로 인정(키확장, 안정 파티션 등).

- 병합 정렬도 구현 방식에 따라 불안정해질 수 있음  
  (동일 키는 왼쪽 우선 복사 등의 규칙 준수 필요).

## 비교 기반 (Comparison-based) vs 비비교 기반 (Non-comparison-based)

### 구분 기준

순서 결정 기준 — 대소 비교 연산 vs 키의 구조·범위

- 비교 기반 정렬: 대소 비교 연산만으로 순서 정렬  
  예시: 퀵, 병합, 힙, 삽입, 선택, 버블, 셸

- 비비교 기반 정렬: 비교 없이 키의 구조/범위만으로 정렬  
  예시: 계수, 기수, 버킷

### 활용도

- 비교 기반:  
  일반적/복잡한 키, 메모리 제한, 안정성/유연성 요구

- 비비교 기반:  
  구조적 정의가 명확한 단순 키

### 참고

- 비비교 기반 정렬은 값의 추가 정보를 기록하는 별도 공간을 요구함  
  → 대부분 비제자리 정렬(Not in-place).

## 내부 정렬 (In-memory) vs 외부 정렬 (External)

<details><summary>외부정렬 심화</summary>

## I/O란?

I/O(Input/Output)는 데이터를 읽고 쓰는 동작을 의미함.  
주로 메모리(RAM)와 저장장치(SSD/HDD) 간 데이터 전송을 가리킴.

CPU는 RAM에 올라와 있는 데이터를 매우 빠른 속도로 처리하는 반면,  
외부 저장장치에서 RAM으로 데이터를 불러오는 속도는 훨씬 느림.  
→ 이러한 불균형 때문에 CPU가 데이터를 기다리며 놀게 되는 상황이 발생.  
→ I/O가 전체 처리 속도를 지연시키는 주요 원인이 됨.

## 접근속도

- RAM (주기억장치):  
  나노초(ns) 단위 접근 속도 (1ns = 10⁻⁹초)  
  대략 수십~수백 ns 수준에서 원하는 주소를 바로 읽고/쓸 수 있음.

- SSD (Solid State Drive):  
  마이크로초(μs) 단위 접근 속도 (1μs = 10⁻⁶초)  
  RAM보다는 수천 배 느림.

- HDD (Hard Disk Drive):  
  밀리초(ms) 단위 접근 속도 (1ms = 10⁻³초)  
  기계식 헤드가 움직여야 하므로 지연이 매우 큼.  
  RAM 대비 수십만 배 이상 느림.

## 외부 정렬이란?

최소한의 I/O로 메모리 용량을 초과하는 데이터를 정렬할 수 있도록 관리하는 절차/전략.

외부 정렬은 디스크 ↔ RAM 간 I/O 속도 자체를 빠르게 만드는 건 불가능함.  
(물리적인 하드웨어 성능 한계이므로 알고리즘으로 바꿀 수 없음.)

- 큰 데이터를 나누어 처리:  
  RAM에 한 번에 못 올릴 만큼 큰 데이터를 쪼개서 정렬.  
  작은 런(run)을 만들고, 이를 차례대로 합쳐 전체 데이터를 정렬하는 “절차”를 정의.

- I/O 효율 관리:  
  I/O 횟수를 최소화 할 수 있도록 절차를 개선하고 다양한 최적화 기법을 활용.

## 작동 흐름

정렬 자체는 메모리에서 수행되며, 외부 정렬과 내부 정렬이 역할 분담하는 방식임

1. 외부 저장 매체 → RAM (읽기: I/O)  
   메모리에 들어올 수 있는 크기만큼 데이터를 블록 단위로 읽어옴.

   이때 외부 정렬은 순차 접근, 큰 블록 단위 읽기,  
   이중 버퍼링/비동기 I/O 같은 기법을 통해 I/O 병목을 줄임.

2. 초기 런(run) 생성 (내부 정렬)  
   RAM 안에서 내부 정렬 알고리즘을 사용하여 해당 블록을 정렬.  
   → 정렬된 파일 파편(=런) 생성.

3. 런을 디스크에 기록 (쓰기: I/O):  
   RAM 용량 제약 때문에 런을 그대로 유지할 수 없으므로,  
   정렬된 런을 외부 저장 장치에 다시 기록함.

4. 다단 병합 (Merging phase - 외부 정렬)  
   RAM이 수용 가능한 범위만큼 여러 런을 '순차적'으로 불러와, k-way 병합 수행  
   → 올바른 순서로 런을 조립함

5. 병합된 결과를 디스크에 순차적으로 기록.  
   이때 올바른 순서대로 기록되며, 다음 단계의 병합 또는 최종 결과로 활용될 수 있음

6. 전체 런이 하나로 합쳐질 때까지 이 과정을 반복.

## I/O 최적화 원리

- 큰 블록 단위로 순차 읽기/쓰기 (랜덤 접근 피하기)

- k-way 병합 (한 번에 여러 런 병합해서 병합 단계 수 줄이기)

- 이중 버퍼링 (이중 버퍼로 I/O와 연산 동시 진행)

- 비동기 I/O ( I/O가 진행되는 동안 CPU는 다른 작업 수행)

</details>

### 핵심

외부 정렬은 I/O 병목 최소화를 위해 설계된 파이프라인  
→ 내부 정렬로 생성된 런을 관리·병합하는 과정을 담당함.

메모리(RAM)에 올라온 데이터는 전부 내부 정렬로 처리됨.  
→ 외부 정렬과 경쟁이 아닌 상호 보완적 역할 분담

### 구분 기준

정렬 데이터의 크기와 메모리 용량

- In-memory: 정렬 대상 데이터 ≤ 메인 메모리 용량  
  → 메모리(RAM)에서 이루어지는 정렬  
  예시: 외부 정렬 외의 정렬

- External: 정렬 대상 데이터 > 메인 메모리 용량  
  → I/O 최적화 및 런 데이터를 관리하는 절차/전략.
  예시: 외부 병합 정렬(다단/다방향 머지)

외부정렬은 DBMS/대용량 로그 처리 등에서 표준적으로 쓰임.

## 적응형 정렬 (Adaptive) vs 비적응형 정렬 (Non-adaptive)

### 구분 기준

입력의 기존 순서 활용 여부  
→ 입력된 데이터의 정렬 정도가 성능에 영향을 끼치는지

- Adaptive: 정렬도에 민감 → 성능에 큰 영향  
  예시: 삽입, Timsort 등

- Non-adaptive: 정렬도와 무관 → 비슷한 성능  
  예시: 선택, 힙, 전통적 병합, 퀵(일반적으로) 등

### 정의

- 적응형 정렬:  
  데이터의 기존 정렬 상태를 감지하고, 그에 따라 수행 과정을 최적화하는 정렬.  
  → 데이터가 정렬되어 있을수록 더 빨라짐.

- 비적응형 정렬:  
  입력의 정렬 여부와 관계없이 항상 동일한 절차를 밟는 정렬.  
  → 데이터가 정렬되어 있어도 복잡도는 변하지 않음.

### 활용도

- 적응형 정렬:  
  실제 환경(로그, 시계열, 데이터베이스 인덱스 등)에서는 부분적으로 정렬된 데이터가 흔함  
  → 대부분의 경우 효율적.

- 비적응형 정렬:  
  데이터의 초기 상태가 예측 불가할 때.  
  항상 안정적이고 균일한 성능을 보장해야 할 때(DBMS, 검색 엔진 등).

## 온라인 알고리즘 (Online) vs 오프라인 알고리즘 (Offline)

### 구분 기준

입력 전체를 미리 알고 있는지, 또는  
입력이 순차적으로 들어올 때 즉시 처리해야 하는지 여부

- Online: 입력에 대해 즉각적으로 순차적으로 처리하는 알고리즘  
  → 최적의 선택 보장 어려움, 대신 실시간 처리 가능.

- Offline: 입력 데이터 전체를 알고 있는 상태에서 처리하는 알고리즘.  
  → 최적의 선택에 유리함, 대신 실시간 처리 불가능.

이러한 알고리즘적 관점의 분류는 정렬에도 적용 가능함.

## 정렬 예시

### 온라인 알고리즘이 적용된 정렬 예시:

- 삽입 정렬 (Insertion Sort):  
  → 데이터가 하나씩 들어올 때 바로 적절한 위치에 삽입

- 힙(Heap) 기반 정렬:  
  → 원소 삽입 시마다 heapify  
  → 현재 입력까지 정렬 상태 유지

- 이진 탐색 트리 기반 정렬:  
  → 입력이 들어올 때마다 트리에 삽입  
  → 중위 순회로 정렬된 결과 조회 가능

### 오프라인 알고리즘이 적용된 정렬 예시

- 퀵 정렬 (Quick Sort)

- 병합 정렬 (Merge Sort)

- 힙 정렬 (Heap Sort)

- 고전 정렬 (선택 / 버블 / 셸 등)

모두 전체 입력을 알고 시작하는 정렬

</details>
<details><summary>버블 정렬 (Bubble Sort)</summary>

## 요약

- 원리: 인접한 두 원소를 비교하여 스왑

- 특징: 비교 기반, 안정적, 제자리, 구현 단순

- 복잡도: 평균/최악 O(n²), 최선 O(n)(조기 종료)

- 활용도: 다른 정렬 사용 추천

## 원리

인접한 두 원소를 비교하여 순서가 잘못되면 스왑하는 비교 기반 정렬

한 번의 패스(전체 순회)가 끝나면 가장 큰 값이 맨 뒤에 고정됨(오름차순 기준)

## 시간·공간·속성

- 시간 복잡도:  
  평균/최악 O(n²), 최선 O(n)(조기 종료 적용 시)

- 공간 복잡도:  
  O(1) (제자리 정렬, in-place)

- 안정성: 안정적(동일 값의 상대 순서 보존)

- 실행 특성: 스왑 횟수가 많아 실제 체감 속도가 느린 편

## 활용처

- 개념 학습: 비교·스왑·패스 개념 설명에 적합

- 거의 정렬된 데이터: 조기 종료가 자주 발생하는 경우

- 작은 입력: 원소 수가 매우 작을 때 간단 구현/시연용

## 한계

- 스왑 비용이 큰 환경에서 특히 비효율적 (데이터 단위의 크기가 큰 경우)

- 입력이 조금만 커져도 O(n²)로 급격히 느려짐 (실 사용 X)

- 동일 난이도라면 삽입 정렬또는 선택 정렬이 더 실용적임

포인터만 변경하는 링크드 리스트의 경우, 스왑 비용은 적지만  
요소에 접근하기 위해 순회하는 비용이 커져서 여전히 비효율적임

## 최적화 로직

- 조기 종료(Early Stopping)
  한 패스 동안 스왑이 없으면 즉시 종료  
  → 최선 O(n) 가능

- 비교 범위 축소(lastSwap 기법)  
  마지막으로 스왑된 위치 이후는 정렬 완료  
  다음 패스에서 해당 인덱스까지만 비교

- 꼬리 구간 생략(고정된 뒤쪽 무시)  
  패스 종료 시 마지막 원소의 위치가 확정되므로,  
  비교 범위를 1씩 줄이는 고정 규칙 적용.

- Cocktail Shaker, Comb, Odd-Even 등 변형이 있음

## 비용 모델(메모리·캐시·분기)

- 메모리: 버블은 스왑 중심 → 쓰기 연산량 많음(스왑당 3회 대입)

- 캐시: 선형 스캔(연속된 인접 원소만 접근)이라 비교 지역성은 좋음

- 분기 예측: 비교-스왑 분기(조건문)가 많아 예측 실패 비용이 누적됨

</details>

<details><summary>선택 정렬 (Selection Sort)</summary>

## 요약

- 원리: 최솟값을 선택해 현재 위치(i)와 스왑

- 복잡도: 비교는 항상 O(n²), 스왑은 최대 n-1

- 성질: 제자리, 불안정, 구현 단순

- 활용도: 쓰기 비용이 매우 큰 환경에서 고려할만함

## 원리

현재 위치 i에서 이후 구간의 최솟값을 찾아  
i와 교환하는 과정을 반복하는 비교 기반 정렬.  
(i = 0 → n-1까지)

한 번의 패스가 끝나면 가장 작은 값이 앞쪽으로 확정됨(오름차순 기준).

## 시간·공간·속성

- 시간 복잡도:
  비교 횟수 ≈ n(n-1)/2 → 최선/평균/최악 모두 O(n²)
  스왑 횟수 ≤ n-1(한 패스에 최대 1회)

- 공간 복잡도:
  O(1) (제자리 정렬, in-place)

- 안정성:
  불안정 정렬(동일 값의 상대 순서가 깨질 수 있음)

## 실행 특성:

비교는 많고, 쓰기(스왑)가 적음 → “쓰기 비용이 비싼 환경”에 적합

## 활용처

- 쓰기 비용이 큰 경우: 데이터 단위가 커 복사 비용이 큰 경우  
  (그래도 n log n 정렬보다는 안좋음)

- 작은 입력: 원소 수가 매우 적은 경우

- 개념 학습: 선택·교환 개념 설명에 용이

## 한계

- 거의 정렬된 경우에도 비교가 줄지 않음

- 대규모 데이터 비적합: O(n log n) 계열(퀵/머지/힙) 대비 현저히 느림

연결 리스트에 적용하면 포인터만 바꿔 스왑 비용은 적지만,  
매 패스마다 최솟값 탐색 순회가 필요해 여전히 O(n²)

## 최적화 로직

- 양방향 선택 정렬(Double Selection):  
  한 패스에서 최솟값과 최댓값을 동시에 찾아 양 끝에 배치  
  → 패스 수는 줄지만 복잡도는 여전히 O(n²)

- 불필요한 스왑 최소화:  
  찾은 최솟값이 이미 제자리면 스왑 생략 → 쓰기 횟수 감소(여전히 ≤ n-1)

- 힙 정렬(Heap Sort)로 확장:  
  선택 과정을 힙(Heap) 자료구조로 구현 → O(log n)

## 비용 모델(메모리·캐시·분기)

- 메모리: 패스당 0~1회 스왑 → 총 스왑 횟수는 n-1 이하

- 캐시:  
  최솟값 탐색이 선형 스캔 중심이므로 공간 지역성이 좋음

- 분기 예측:  
  '현재 최솟값 갱신 여부' 분기가 반복되나, 스왑 분기 빈도는 낮음

</details>

<details><summary>삽입 정렬 (Insertion Sort)</summary>

## 요약

- 원리:  
  배열을 왼쪽(정렬)과 오른쪽(미정렬)으로 나눈 후,  
  오른쪽(미정렬)에서 뽑아, 왼쪽(정렬)의 알맞은 위치에 삽입.

- 복잡도: 평균/최악 O(n²), 최선 O(n)

- 성질: 안정적, 제자리, 작은 입력/거의 정렬된 데이터에 적합

- 활용도: 단독 주력보단 소규모 구간/보조 루틴으로 사용

## 정의

배열을 “정렬된 부분”과 “미정렬 부분”으로 나누고, 미정렬 부분에서 원소를 하나씩 꺼내어  
정렬된 부분의 알맞은 위치에 삽입하여 전체를 정렬하는 알고리즘

## 원리

1. 배열을 두 부분으로 나눔

   - 왼쪽: 이미 정렬된 부분
   - 오른쪽: 아직 정렬되지 않은 부분

2. 미정렬 구간의 첫 원소(i 번째)를 current로 설정

3. 정렬된 부분의 오른쪽 끝( j = i-1 )부터 역방향으로 탐색

4. j > current 일 경우 array[i] = array[j]로 덮어쓴 후 다음 인덱스로 이동( j-- )

5. 4번을 반복하다 올바른 위치에 current 값 삽입.

6. 이 과정을 i = 1 → n-1까지 반복.

덮어쓰면서 이동하기 때문에 기존 원소를 밀어내는 것처럼 표현됨

버블 정렬, 선택정렬과는 다른 덮어쓰기 방식으로 진행됨.

- 1회 이동 = array[j+1] = array[j] = 대입 1회
- 1회 삽입 = array[j+1] = current = 대입 1회

- 불변식: [0..i) 구간은 항상 정렬됨

<details><summary> 구간 표기법</summary>

## 구간 표기법

대괄호 [ 또는 ] → 해당 끝점을 포함한다(inclusive)

소괄호 ( 또는 ) → 해당 끝점을 포함하지 않는다(exclusive)

## [0..i)의 의미

- 0은 포함됨 → 구간 시작점 포함 (0번째 원소는 정렬된 집합에 포함)

- i는 포함되지 않음 → 구간 끝점 제외 (i번째 원소는 아직 정렬 구간에 포함되지 않음)

- “0번 인덱스부터 i-1번 인덱스까지는 항상 정렬돼 있다”

</details>

## 시간·공간·속성

- 시간 복잡도:

  - 최악(역순 배열): 각 원소가 끝까지 밀리므로 총 대입 ≈ n(n-1)/2 + n ≈ O(n²)
  - 최선(이미 정렬): 각 단계에서 삽입만 1회 → 총 대입 ≈ n

- 공간 복잡도: O(1) (제자리 정렬, in-place)

- 안정성: 안정적(동일 키의 상대 순서 보존)  
  구현 시 > 비교만 사용(동일 값 원소의 상대적 순서 유지)

- 실행 특성: 이동(shift) 중심이라 인접 메모리 쓰기 → 캐시 친화적

- 작은 입력·거의 정렬된 데이터에서 체감 성능이 좋음

## 활용처

- 작은 데이터셋: 상수항이 작아 실사용에서도 빠르게 동작

- 거의 정렬된 데이터: 최선 O(n)에 근접

- 하이브리드 정렬 보조 루틴: 퀵/머지/팀소트 등에서 작은 입력 처리

## 한계

- 무작위·역순 데이터에서는 이동이 많아 성능이 안좋음(O(n²))

- 대규모 데이터에서 O(n log n) 계열보다 성능이 안좋음

- 연결 리스트: 삽입 자체는 O(1) 이지만, 위치 찾기 순회가 필요함 (전체 O(n²))

## 최적화 방법

- 조기 종료:  
  왼쪽 탐색 중 현재 원소 ≤ 키를 만나면 즉시 중단 → 이미 그 앞은 모두 ≤ 키  
  이미 정렬된 배열에서 비교 n-1회, 이동 0회 → O(n)

- 이진 탐색 삽입(Binary Insertion Sort):  
  삽입 위치 탐색을 이진 탐색(O(log n))으로 수행  
  → 비교 횟수 감소, 전체는 여전히 O(n²)

  비교가 비싼 환경(복잡한 키 비교)에서 유의미

- 셸 정렬(Shell Sort)로 확장:  
   멀리 떨어진 원소 정렬시 많은 이동이 필요하다는 기존의 단점을 보완.  
   \
   간격(gap) 을 두고 떨어진 원소들끼리 먼저 부분 정렬한 뒤,  
   점점 간격을 줄여가면서 전체를 정렬하는 알고리즘  
   → O(n^(3/2)) ~ O(n log² n) 수준까지 개선 가능 (최악은 구현/시퀀스에 따라 O(n²))

- 센티넬(Sentinel) 기법:
  배열 맨 앞에 "절대 최소값"을 넣어두고,  
  반복문에서 경계 검사(j >= 0)를 없애는 방식.  
  → index 검사를 기존 비교 조건으로도 수행할 수 있도록 만드는 트릭

## 비용 모델(메모리·캐시·분기)

- 메모리: 연속 이동(shift) → 스왑 대비 쓰기 패턴이 효율적

- 캐시: 왼쪽으로 연속 접근하므로 공간 지역성↑

- 분기 예측: 크기 비교 단일 분기 반복 → 정렬될수록 예측 성공률↑

</details>

<details><summary>병합 정렬 (Merge Sort)</summary>

## 요약

- 원리 : 분할(반씩 쪼갬) → 정복(각자 정렬) → 병합(두 정렬된 리스트를 합침)

- 시간 복잡도: 항상 Θ(n log n) (최선/평균/최악 동일)

- 공간 복잡도:

  - 배열:  
    버퍼 - Θ(n), 스택 - 재귀 O(log n) / 총 - O(n)
  - 연결 리스트:  
    버퍼 - O(1), 스택 - 재귀 O(log n) / 반복 O(1), 총 - 최대 O(1)

- 안정성: 안정 정렬(동일 키의 상대 순서 보존; 동등비교 시 왼쪽 우선 선택)

- 활용: 대용량/안정성 요구 환경, 외부 정렬(디스크), 하이브리드 정렬

함수 호출 스택이란?

## 원리(분할·정복)

lo: 구간의 시작 인덱스 (low)  
hi: 구간의 끝 인덱스 (high)  
mid: 구간의 가운데 인덱스 (middle)

### 분할(Divide)

배열을 왼쪽 A[lo..mid], 오른쪽 A[mid+1..hi] 와 같이 분할

분할 자체는 인덱스 연산 → O(1)

### 정복(Conquer)

두 하위 배열에 동일한 분할 알고리즘을 재귀/반복 적용

길이가 0 또는 1이면 (기저조건) 이미 정렬되었다고 간주 후 재귀 종료.

### 병합(Merge)

정렬된 두 구간을 두 포인터로 한 번 훑으며 합침

한쪽이 소진되면 나머지 전부 복사

### 병합의 불변식

결과 배열의 접두사(prefix)는 항상 정렬됨

다음 후보는 왼쪽 i, 오른쪽 j의 최소값 중 하나

동등 비교 시 왼쪽을 먼저 택하면 안정성 보장

시간 분석 직관

병합은 각 원소를 정확히 한 번 출력 → Θ(n)

재귀 트리 깊이 log₂ n, 각 레벨에서 총 작업량 n → n log n

## 시간·공간·속성

- 시간: 최선/평균/최악 Θ(n log n) → 성능이 일정함

- 공간:

  - 배열: 버퍼 Θ(n), 재귀 스택 O(log n),
    Bottom-up(반복) + 공유 보조배열(aux) 로 스택 제거 가능

  - 연결 리스트: 버퍼(포인터 재연결) O(1)

- 안정성: 안정적

- 적응성: 기본형은 비적응적, “런(run) 감지”로 보완 가능

## 활용처

- 안정성이 필요한 대규모 정렬

- 외부 정렬(External Sort): 메모리 크기를 초과한 데이터 정렬(로그, 트랜잭션)

- 연결 리스트 정렬: 포인터 재배치

- 하이브리드 정렬: Timsort 등에서 런 감지 + 병합

## 최적화

- 작은 구간 삽입 정렬(Threshold): 작은 구간은 삽입 정렬로 처리 → 상수항 절감

- 이미 정렬이면 병합 생략: left.last ≤ right.first면 O(n) 병합 생략

- 보조배열 재사용: 호출마다 새 배열 대신 공유 aux 사용 → 할당/복사 비용 감소

- Bottom-up(반복형): run 크기 1,2,4,8…로 키워가며 인접 블록 병합 → 스택 오버헤드 0, 캐시 친화 개선

- 자연 병합(Natural Mergesort): 입력에서 증가/감소 런을 감지해 바로 병합 → 실효 성능↑(팀소트의 핵심)

- 연결 리스트 분할/병합: slow/fast로 중앙 분할, 포인터만 재연결해 안정 병합

- 외부 정렬 최적화: k-way merge(힙) 로 I/O 최소화, replacement selection으로 더 긴 run 생성

- 병렬화: 좌/우 분할을 병렬 처리, 병합도 분할 병합으로 병렬화(워크 스틸링 등)

- 센티넬 사용: 경계 체크 분기 제거(저수준 언어에서 유용)

## 비용 모델(메모리·캐시·분기)

- 메모리: 배열은 버퍼 왕복 복사가 필요 → 쓰기량 큼(보조배열 재사용으로 완화)

- 캐시: 병합은 선형 스트리밍 읽기/쓰기 → 캐시/디스크 접근 패턴에 유리

- 분기 예측: 두 포인터 비교 분기 반복. 런 감지/병합 생략으로 분기 수 자체를 줄일 수 있음

</details>

<details><summary>퀵 정렬 (Quick Sort)</summary>

## 요약

- 원리: 임의의 피벗(pivot)을 기준으로 값 분할(partition) → 좌/우 구간에 재귀 적용(분할 정복)

- 시간 복잡도: 평균/보통 Θ(n log n), 최악 Θ(n²)(나쁜 분할 연속 시 - 분할 시 원소 쏠림)

- 공간 복잡도: O(log n)(재귀 스택 제어 방식에 따라 최악 O(log n)까지 제한 가능)

- 안정성: 불안정(기본) / 안정(안정 파티션 + 추가 공간 O(n) 필요 - 보조배열 활용)

- 활용도: 대부분의 인-메모리 정렬 상황, 안정성 필요X, 중간규모 데이터에 적합

## 원리(분할·정복)

- 분할: 피벗보다 작은 요소와 큰 요소로 배열을 제자리(in-place) 재배치

- 정복: 분할된 두 구간을 같은 방식으로 정렬

- 결합: 퀵정렬은 병합 단계가 사실상 없음(분할 시 재배치가 끝)

## 파티션

- 정의:  
  배열을 피벗을 기준으로  
  [ 작은 값들 | (피벗과 같은 값들) | 큰 값들]  
  형태로 재배치해, 피벗(구간)이 최종 정렬된 위치에 놓이도록 만드는 절차.  
  → 이후 파티션 양쪽 값 재귀 정렬 후 병합

- 공통 불변식: 스캔이 진행되는 동안,
  - 왼쪽 블록: 피벗보다 작은 값들
  - 가운데(선택적): 피벗과 같은 값들(3-way인 경우)
  - 오른쪽 블록: 피벗보다 큰 값들

스캔 포인터가 앞으로 나아가도 구간 구분은 항상 유지

## 대표 파티션 방식

### Lomuto 파티션

- 특징: 피벗을 구간의 끝에 두고(A[high]) 왼쪽에서 오른쪽으로 스캔(for j = low to high - 1:)  
  → 작은 원소들을 앞쪽으로 스왑하며 피벗보다 작은 구간을 넓혀감

- 장점: 구현이 단순함

- 단점: 불필요한 스왑이 많고 분기 예측에 취약 → 실측상 느린 편

- 불변식 요지: 스캔 인덱스 앞쪽은 [< pivot] / 나머지는 [≥ pivot]

      LomutoPartition(A, low, high):
      pivot = A[high] // 피벗은 배열 끝 원소
      i = low - 1 // i = 피벗 이하 구간의 끝 인덱스
      for j = low to high - 1: // j = 검사할 인덱스
          if A[j] <= pivot: // 검사한 인덱스가 피벗 이하라면
              i = i + 1 // 이하 구간 1칸 확장
              swap A[i] <-> A[j] // 이하 구간의 끝으로 스왑
      swap A[i+1] <-> A[high] // 마지막으로 피벗을 이하 구간 끝과 스왑
      return i+1   // pivot의 최종 위치

### Hoare 파티션 (양끝)

- 특징: 양끝 포인터가 안쪽으로 이동하며 잘못된 쌍을 발견하면 교환

- 장점: 스왑 수가 적고 실제 성능이 좋은 경우가 많음

- 주의:  
  pivot과 동일한 값이 여러 개 있을 수 있고,  
  pivot을 고정시키지 않고 경계만 나누기 때문에,  
  반환 위치가 피벗 최종 인덱스와 일치하지 않을 수 있음  
  → 이후 재귀 범위 지정 주의

      HoarePartition(A, low, high):
      pivot = A[low]          // 보통 첫 원소
      i = low - 1 // 왼쪽 끝
      j = high + 1 // 오른쪽 끝
      while true:
          repeat i = i + 1 until A[i] >= pivot // 이하 구간에서 이상 값 탐색
          repeat j = j - 1 until A[j] <= pivot // 이상 구간에서 이하 값 탐색
          if i >= j: return j // i ≥ j가 되면 j를 반환 → 분할 경계
          swap A[i], A[j] // 잘못된 쌍 교환

### 원리:

이하 구간에서 이상 값 발견 시 멈추고, 이상 구간에서 이하 값 발견시 멈춤 → 잘못된 쌍 교환

### 3-way 파티션 (Dutch National Flag)

구간을 < pivot / = pivot / > pivot 세 부분으로 즉시 분할

중복 원소(키)가 많을 때 유리함 (예시: [3,3,3,3,3]은 한 번에 처리)

안정성은 보장하지 않지만, 중복 처리에 유리함

### 불변식

- a[lo .. lt-1] : < pivot

- a[lt .. i-1] : = pivot

- a[i .. gt] : 미확인(?)

- a[gt+1 .. hi] : > pivot

### 포인터 약자

- lt = less-than 경계(“< 구간의 끝 다음 칸”)

- gt = greater-than 경계(“> 구간의 시작 직전 칸”)

- i = 현재 검사 중인 인덱스

### 처리 규칙 (선형 스캔)

- a[i] < pivot → swap(a, lt, i); lt++; i++; (< 구간 확장)

- a[i] == pivot → i++; (= 구간 확장)

- a[i] > pivot → swap(a, i, gt); gt--; (> 구간 확장; i는 재검사)

i > gt가 되면 세 구역 완성

      function swap(a, i, j) {
        // 배열 a에서 i, j 위치 교환
        const t = a[i];
        a[i] = a[j];
        a[j] = t;
      }

      function partition3way(a, lo, hi, cmp = (x,y)=>x<y?-1:x>y?1:0) {
        let lt = lo,    // pivot보다 작은 구간의 끝 다음 위치
        i  = lo + 1,    // 현재 검사 중인 인덱스
        gt = hi;        // pivot보다 큰 구간의 시작 직전 위치
        const pivot = a[lo]; // 왼쪽 끝 = 피벗
        while (i <= gt) {
          const c = cmp(a[i], pivot); // 현재 값과 피벗 비교
          if (c < 0) swap(a, lt++, i++); // 스왑 후 작은 구간 확장 + 검사 인덱스 증가
          else if (c > 0) swap(a, i, gt--); // 스왑 후 큰 구간 확장 + 인덱스 유지
          (맨 뒤 원소와 교환했으므로 다음 검사때 같은 인덱스를 검사해야함)
          else i++; // 동일 값인 경우 다음 인덱스 검사
        }
        // equal block 범위 [lt, gt] 반환
        // 이 구간은 pivot과 같은 값들이 모여 있고, 정렬이 이미 끝난 상태
        return { lt, gt };
      }

## 시간·공간·속성

- 시간: 평균/보통 Θ(n log n), 최악 Θ(n²)(극단적 분할: 1 vs n-1)

피벗 선택과 3-way 사용으로 최악 확률을 크게 낮춤

- 공간(스택): 평균 O(log n)  
  “작은 쪽 먼저 재귀 + 큰 쪽은 루프로(꼬리 재귀 제거)”  
  → 최악도 O(log n) 로 제한

- 안정성: 불안정

안정이 필요하면 안정 파티션(추가 버퍼) 또는 다른 정렬(팀소트/병합)을 고려

## 퀵정렬의 대표적 “종류/변형”

### 파티션 방식

- Lomuto: 단순, 스왑 많음(교육/참고용)

- Hoare: 실 성능 우수, 단 피벗 위치가 아닌 경계 반환

- 3-way: 중복 키 많을 때 최고 선택

## 최적화

### 피벗 전략

- 고정 피벗(첫/끝): 구현 간단하나 최악 빈번

- 랜덤 피벗: 평균적 균형 개선, 편향 데이터 방지

- Median-of-3(첫/중간/끝의 중앙값): 극단 분할 완화, 상수항 개선

- Tukey’s ninther: median-of-3을 3번 후 중앙값 → 매우 견고

- Median-of-Medians(선형시간 선택): 최악 O(n log n) 보장 가능(상수항 큼; 학술/특수용)

### 하이브리드 정렬

- 인트로소트(Introsort):  
  퀵정렬 시작 → 깊이 한도 초과 시 힙정렬로 전환

- 작은 구간 삽입정렬:  
  작은 구간은 삽입 정렬로 처리(상수항 절감)

- 듀얼-피벗 퀵정렬:  
  두 피벗으로 3구간 분할

## 비용 모델(메모리·캐시·분기)

- 메모리 :  
  스왑 중심(버블보다 적고, 병합보다 훨씬 적음)

- 캐시 :  
  제자리 + 양끝→중앙 스캔으로 지역성 양호(무작위 스왑은 불가피)

- 분기 예측:  
  파티션의 다수 분기가 실속도 좌우 → 3-way/샘플링/블록화로 완화

## 다른 정렬과 비교

- 병합 정렬: 항상 Θ(n log n) + 안정 + 외부정렬/연결리스트에 강함 / 추가 메모리 필요

- 퀵정렬: 보통 더 빠른 상수항/캐시 효율, 최악 O(n²)(하이브리드로 보완)

- 힙 정렬: O(n log n) + O(1) 공간 + 최악 보장 / 캐시·상수항 불리 → 실측은 퀵 < 힙

- 삽입/선택: O(n²) 계열, 작은 구간에서만 보조로 유리

## 활용처

- 메모리 내 정렬이 거의 다 됐을 때(특히 참조/기본형의 큰 배열)

- 안정성이 꼭 필요하지 않을 때

- 중복 키가 많다면 3-way를 우선 고려

- 최악 보장이 필요하면 인트로소트(퀵 + 힙 fallback)

</details>

<details><summary>상수항과 상수계수</summary>

- 참조:  
  https://usaco.guide/bronze/time-comp?lang=cpp  
  https://en.wikipedia.org/wiki/Time_complexity  
  https://stackoverflow.com/questions/22614585/what-is-constant-factors-and-low-order-term-in-algorithms

## 정의

### 상수항(Constant term):

입력 크기 n과 무관하게, 알고리즘 구현 중  
 실행하지 않으면 안되는 처리들이 낳는 비용을 모두 합친 더하기 항.  
 (고정 횟수로 수행되는 초기화/마무리, 소규모 I/O, 상수 크기 메모리 할당 등)

### 상수계수(Constant factor):

입력 크기와 무관하게, 알고리즘의 핵심 단계가 한 번 실행될 때마다 발생하는 고정 비용의 합.

Stack Overflow

      입력 크기에 무관하게 반복되는 핵심 연산당 곱해지는 상수 값. 실질 속도에 영향을 줌.
      Stack Overflow

위키백과

      연산 1회당 고정 시간으로, 지배항 앞에 등장하는 상수.	Wikipedia

USACO Guide

      같은 시간복잡도라도 연산 종류나 구현에 따라 다르게 나타난다.	USACO Guide

### 예시

- T(n) = an + c → O(n) 에서 상수계수 = a, 상수항 = c

- T(n)=a nlogn + bn + c → O(nlogn) 에서 상수계수 =a

* 상수항 / 상수계수 최적화:  
  차수는 그대로 두되 a,b,c 를 줄여 실제 시간을 빠르게 만드는 것

## 성능에 미치는 영향

### 알고리즘 간 상수 계수 차이

같은 빅오라도 구현 상수 계수 차이로 실측 속도가 달라짐.

### 예시

퀵정렬과 병합정렬은 둘 다 O(nlogn)이지만,  
비교·이동·메모리 사용·캐시 지역성 등 상수 비용의 차이로 실측 성능이 달라짐

### 최적화 예시

- 입력 특성(메모리 제약, 안정성, 정렬도)에 맞는 알고리즘 선택.

- 실측 기반 선택(마이크로벤치, 프로파일링).

## 상수항 최적화가 효과적일 때

- 차수 개선이 어렵거나 이미 최적일 때  
  → 방법론 적으로는 더이상 개선이 어려울 때

- 짧은 입력 범위/짧은 런타임(치명적 상수비용이 전체의 대부분).

- I/O 바운드/메모리 바운드 상황(차수보다 고정 지연이 지배).

### 주의사항

- 가독성과 안전성 고려
- 프로파일링으로 확인된 병목 지점에만 적용

## 연산 단위 비용

### 정의

기본(단위) 연산 1회의 비용.  
(덧셈/곱셈/비교/분기 등)

### 최적화 예시

- 비교·대입을 줄인 코드 경로 선택.
- 조건문 대신 수학/비트 연산으로 대체 (분기 제거).
- 고비용 연산을 저비용 연산으로 대체 (나눗셈 → 시프트/곱셈).

## 메모리 접근 비용

### 정의

동일 연산이라도 메모리 배치/캐시 적중률에 따라 달라지는 상수 비용  
→ 캐시 친화도 차이에 따른 상수 비용

### 최적화예시

- 데이터 레이아웃 정리: 순차 접근, struct 및 패딩 최소화
- 블록/타일링: 타일 단위로 접근해 캐시 재사용 극대화.

## 루프·함수 호출 오버헤드

### 정의

루프 제어(i++, 조건 확인 등)나 함수 호출 스택 관리 비용  
(루프 인덱스 증가, 경계 체크, 함수 호출 프롤로그/에필로그 같은 제어 비용 등)

### 최적화 예시

- 루프 전개(loop unrolling)
- 인라이닝(inlining)
- 경계 체크 제거
- 재귀를 반복으로 대체(스택 프레임 비용 절감).

## I/O 오버헤드:

### 정의

디스크/네트워크 접근 시 발생하는 기본 지연(latency)

### 최적화 예시

- 배치/버퍼링/블록 사용
- 비동기 I/O / 이중 버퍼링
- 순차 I/O 위주로 설계(랜덤 접근 회피).

## 분기(branch) 비용

### 정의

분기 예측 실패 시 파이프라인 flush로 발생하는 비용

### 최적화 예시

- 불필요한 if 제거
- 데이터 재배열(정렬해 편향 강화)
- 분기 없는 연산 사용
- 조건의 빈도 높은 경로를 핫패스로.

## 할당/해제 및 동기화 오버헤드

### 정의

메모리 관리(malloc/new/free, GC)와 락/원자 연산의 고정 비용.

### 최적화 예시

- 풀링(pooling)
- Arena/Region alloc
- 락 범위 축소
- 락 없는 구조(CAS, ring buffer) 채택.

## 언어/런타임 상수 비용 (이해 안됨)

### 정의

언어/런타임이 제공하는 안전성·동적 기능 때문에 생기는 부가 비용  
(바운드 체크, 가상 호출, 인터프리터/VM, 박싱/언박싱 등)

### 예시

- Java/Kotlin/Rust: 배열 범위 체크가 루프마다 수행
- C++/Java/C#: 가상 함수 호출로 인한 간접 분기(예측 어려움)
- Python/JS: 동적 타입 + 인터프리터 오버헤드, 객체 박싱
- GC 언어: 할당 빈번 + write barrier로 상수 증가

### 최적화 예시

- 체크 제거 유도: 인덱스 범위를 컴파일러가 유추하도록 루프 구조 단순화, 길이 사전 검증

- 탈가상화/디스패치 단순화: 모노모픽 호출 유지, final/sealed/CRTP로 devirtualization 유도

- 인라이닝·벡터화가 잘 먹히게 코드 패턴 단순화

- 박싱 회피: 원시 타입 컬렉션 사용, escape analysis로 스택 할당 유도

- JIT/VM: 워밍업 비용을 배제한 상태에서 성능 측정(steady state)

</details>
</details>
