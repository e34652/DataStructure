<details><summary>알고리즘과 시간 복잡도</summary>

## 정의

- 알고리즘 분석: 알고리즘이 소모하는 자원(시간·메모리)을 분석하는 것

- 시간 복잡도: 속도 관점
- 공간 복잡도: 메모리 사용량 관점

알고리즘을 시간과 공간의 관점에서 분석하며  
일반적으로 시간에 초점을 두어 평가함.

실행시간은 실행환경에 따라 달라지므로, 연산 횟수 증가율을 기준으로 분석함.

점근적 표기법을 사용하여 입력 크기(n)가 커질 때의 증가율을 표현

## 점근적 표기법

실행 시간이나 메모리 사용량을 T(n)으로 두고(입력 크기
n에 대한 함수),  
n→∞일 때의 증가율을 Big-O, Ω, Θ로 표현.

### 종류

### 2) 세 가지 점근적 표기법

- Big-O (O) — 상한 (최악/증가율 최대치)
  최악의 경우, 가장 느린 경우를 의미  
  예시: 삽입 정렬은 O(n²) = 가장 느린 경우에 n²

- Big-Ω (Ω) — 하한 (최소 보장)
  최선의 경우, 가장 빠른 경우를 의미  
  예시: 삽입 정렬은 Ω(n) = 가장 빠를 경우에 n

- Big-Θ (Θ) — 상하한 동일
  최선과 최악이 같아, 실제 성능이 일정한 경우
  예시: 이분 탐색은 Θ(log n) = 성능이 일정함

- 그외에도 Little-o, Little-ω 등이 있음

## 주요 복잡도

### O(1) — 상수 시간

- 입력 크기 `n`과 무관하게 일정한 수행 시간
- 예시: 배열 인덱스로 접근 `arr[i]`
- 그래프: 평평한 선

### O(log n) — 로그 시간

- 입력 크기를 절반씩 줄이는 과정
- 예시: 이분 탐색, 균형 이진트리 탐색
- 특징: `n`이 2배 → 연산 횟수는 1 증가

### O(n) — 선형 시간

- 입력 크기에 비례
- 예시: 배열 전체 순회, 선형 탐색
- 특징: 입력 2배 → 수행 시간도 2배

### O(n log n) — 로그-선형 시간

- 선형 반복 + 로그 단계 결합
- 예시: 퀵/머지/힙 정렬
- 특징: `O(n²)`보다는 훨씬 작음

### O(n²) — 이차 시간

- 중첩 반복문에서 발생
- 예시: 버블 정렬, 삽입 정렬, 플로이드-워셜
- 특징: `n=1000 → 1,000,000 연산`

### O(2^n) — 지수 시간

- 입력 1 증가 → 연산량 2배
- 예시: 부분집합 탐색, 피보나치 재귀
- 특징: `n=30` → 수억 단위 연산

### O(n!) — 팩토리얼 시간

- 가능한 모든 순서 탐색
- 예시: 외판원 문제 완전탐색, 순열 생성
- 특징: `n=20` → 2.4조 연산

### 그 외

- **O(√n)**: 약수 찾기
- **O(log log n)**: 로그를 반복 적용하는 경우
- **O(α(n))**: inverse Ackermann 함수, 거의 상수

## 분할상환(Armortized) 복잡도

- 알고리즘의 여러 연산을 묶어 평균화 하는 분석 기법.
- 알고리즘의 성능에 영향을 미치는 다른 요인들을 전부 고려함.
- 각 연산의 평균 수행성능을 보장함.

## 보완/추가 개념

### 실제 체감 차이

- 작은 입력에서는 O(n²) 정렬이 더 빠를 수 있음 (상수항·구현 단순성)
- 실무에서는 하이브리드 정렬 사용 (팀소트, 인트로소트)

</details>

<details><summary> 분기 예측이란?</summary>

## 분기 예측이란?

CPU는 파이프라인 방식으로 “앞으로 실행할 명령어”를 미리 가져와서 준비함.  
if (a > b) 같은 조건문(분기)이 나오면, 결과를 모른 채로 실행해야 함.

그래서 CPU가 결과를 예상하여 명령어를 미리 준비함.

예상이 맞으면 그대로 진행하지만, 예상이 틀리면 준비한 명령어들을 버리고 다시 로드해야함.  
→ 큰 성능 손해가 발생

## 대안

- 조건문 없는 스왑 기법 (branchless swap):  
  조건문을 연산으로 대체해, 항상 같은 실행 경로를 밟게 만드는 방법.

- 정렬 네트워크(sorting network):  
  분기 대신 고정된 비교·교환 패턴으로 동작

- 데이터 정렬 전처리:  
  입력이 거의 정렬돼 있다면 분기 예측 성공률이 높아짐.

</details>

<details><summary>정렬 알고리즘 분류1</summary>

## 제자리 정렬 (In-place) vs 비제자리 정렬 (Not in-place)

### 구분 기준

정렬 중 추가 보조 공간 사용량 기준

- In-place: 추가 공간이 O(1) ~ 재귀 스택 포함 O(log n)  
  예시: 삽입, 선택, 퀵(제자리 파티션), 힙

- Not in-place: 보조 배열 등 O(n) 추가 공간 활용  
  예시: 배열 기반 병합, 계수, 기수

### 활용도

- 제자리 정렬:  
  메모리 제한되는 환경

- 비제자리 정렬:  
  안정성이 필요 하거나 선형 시간 목표

### 참고

- 일부 엄격한 정의에선 O(1) 만 In-place로 인정.
- 연결 리스트 병합 정렬(반복형)의 포인터 재연결은 O(1) = in-place

## 안정 정렬 (Stable) vs 불안정 정렬 (Unstable)

### 구분 기준

정렬 후 동일 키의 상대 순서 보존 여부

- Stable: 동일 키의 상대 순서가 유지됨  
  예시: 버블, 삽입, 병합(동일 키는 ‘왼쪽 먼저’ 병합 시), Timsort 등

- Unstable: 동일 키의 상대 순서가 바뀔 수 있음  
  예시: 선택, 퀵, 힙, 셸 등

### 활용도

- 안정 정렬:  
  다중 키 정렬(2차, 3차 정렬), 동일 키의 순서 보존

- 불안정 정렬:  
  안정성 불필요, 메모리 제약, 상수항 / 캐시 이점 중시

### 참고

- 불안정 알고리즘도 보조수단을 통한 안정화 시,  
  안정 알고리즘으로 인정(키확장, 안정 파티션 등).

- 병합 정렬도 구현 방식에 따라 불안정해질 수 있음  
  (동일 키는 왼쪽 우선 복사 등의 규칙 준수 필요).

## 비교 기반 (Comparison-based) vs 비비교 기반 (Non-comparison-based)

### 구분 기준

순서 결정 기준 — 대소 비교 연산 vs 키의 구조·범위

- 비교 기반 정렬: 대소 비교 연산만으로 순서 정렬  
  예시: 퀵, 병합, 힙, 삽입, 선택, 버블, 셸

- 비비교 기반 정렬: 비교 없이 키의 구조/범위만으로 정렬  
  예시: 계수, 기수, 버킷

### 활용도

- 비교 기반:  
  일반적/복잡한 키, 메모리 제한, 안정성/유연성 요구

- 비비교 기반:  
  구조적 정의가 명확한 단순 키

### 참고

- 비비교 기반 정렬은 값의 추가 정보를 기록하는 별도 공간을 요구함  
  → 대부분 비제자리 정렬(Not in-place).

## 내부 정렬 (In-memory) vs 외부 정렬 (External)

<details><summary>외부정렬 심화</summary>

## I/O란?

I/O(Input/Output)는 데이터를 읽고 쓰는 동작을 의미함.  
주로 메모리(RAM)와 저장장치(SSD/HDD) 간 데이터 전송을 가리킴.

CPU는 RAM에 올라와 있는 데이터를 매우 빠른 속도로 처리하는 반면,  
외부 저장장치에서 RAM으로 데이터를 불러오는 속도는 훨씬 느림.  
→ 이러한 불균형 때문에 CPU가 데이터를 기다리며 놀게 되는 상황이 발생.  
→ I/O가 전체 처리 속도를 지연시키는 주요 원인이 됨.

## 접근속도

- RAM (주기억장치):  
  나노초(ns) 단위 접근 속도 (1ns = 10⁻⁹초)  
  대략 수십~수백 ns 수준에서 원하는 주소를 바로 읽고/쓸 수 있음.

- SSD (Solid State Drive):  
  마이크로초(μs) 단위 접근 속도 (1μs = 10⁻⁶초)  
  RAM보다는 수천 배 느림.

- HDD (Hard Disk Drive):  
  밀리초(ms) 단위 접근 속도 (1ms = 10⁻³초)  
  기계식 헤드가 움직여야 하므로 지연이 매우 큼.  
  RAM 대비 수십만 배 이상 느림.

## 외부 정렬이란?

최소한의 I/O로 메모리 용량을 초과하는 데이터를 정렬할 수 있도록 관리하는 절차/전략.

외부 정렬은 디스크 ↔ RAM 간 I/O 속도 자체를 빠르게 만드는 건 불가능함.  
(물리적인 하드웨어 성능 한계이므로 알고리즘으로 바꿀 수 없음.)

- 큰 데이터를 나누어 처리:  
  RAM에 한 번에 못 올릴 만큼 큰 데이터를 쪼개서 정렬.  
  작은 런(run)을 만들고, 이를 차례대로 합쳐 전체 데이터를 정렬하는 “절차”를 정의.

- I/O 효율 관리:  
  I/O 횟수를 최소화 할 수 있도록 절차를 개선하고 다양한 최적화 기법을 활용.

## 작동 흐름

정렬 자체는 메모리에서 수행되며, 외부 정렬과 내부 정렬이 역할 분담하는 방식임

1. 외부 저장 매체 → RAM (읽기: I/O)  
   메모리에 들어올 수 있는 크기만큼 데이터를 블록 단위로 읽어옴.

   이때 외부 정렬은 순차 접근, 큰 블록 단위 읽기,  
   이중 버퍼링/비동기 I/O 같은 기법을 통해 I/O 병목을 줄임.

2. 초기 런(run) 생성 (내부 정렬)  
   RAM 안에서 내부 정렬 알고리즘을 사용하여 해당 블록을 정렬.  
   → 정렬된 파일 파편(=런) 생성.

3. 런을 디스크에 기록 (쓰기: I/O):  
   RAM 용량 제약 때문에 런을 그대로 유지할 수 없으므로,  
   정렬된 런을 외부 저장 장치에 다시 기록함.

4. 다단 병합 (Merging phase - 외부 정렬)  
   RAM이 수용 가능한 범위만큼 여러 런을 '순차적'으로 불러와, k-way 병합 수행  
   → 올바른 순서로 런을 조립함

5. 병합된 결과를 디스크에 순차적으로 기록.  
   이때 올바른 순서대로 기록되며, 다음 단계의 병합 또는 최종 결과로 활용될 수 있음

6. 전체 런이 하나로 합쳐질 때까지 이 과정을 반복.

## I/O 최적화 원리

- 큰 블록 단위로 순차 읽기/쓰기 (랜덤 접근 피하기)

- k-way 병합 (한 번에 여러 런 병합해서 병합 단계 수 줄이기)

- 이중 버퍼링 (이중 버퍼로 I/O와 연산 동시 진행)

- 비동기 I/O ( I/O가 진행되는 동안 CPU는 다른 작업 수행)

</details>

### 핵심

외부 정렬은 I/O 병목 최소화를 위해 설계된 파이프라인  
→ 내부 정렬로 생성된 런을 관리·병합하는 과정을 담당함.

메모리(RAM)에 올라온 데이터는 전부 내부 정렬로 처리됨.  
→ 외부 정렬과 경쟁이 아닌 상호 보완적 역할 분담

### 구분 기준

정렬 데이터의 크기와 메모리 용량

- In-memory: 정렬 대상 데이터 ≤ 메인 메모리 용량  
  → 메모리(RAM)에서 이루어지는 정렬  
  예시: 외부 정렬 외의 정렬

- External: 정렬 대상 데이터 > 메인 메모리 용량  
  → I/O 최적화 및 런 데이터를 관리하는 절차/전략.
  예시: 외부 병합 정렬(다단/다방향 머지)

외부정렬은 DBMS/대용량 로그 처리 등에서 표준적으로 쓰임.

## 적응형 정렬 (Adaptive) vs 비적응형 정렬 (Non-adaptive)

### 구분 기준

입력의 기존 순서 활용 여부  
→ 입력된 데이터의 정렬 정도가 성능에 영향을 끼치는지

- Adaptive: 정렬도에 민감 → 성능에 큰 영향  
  예시: 삽입, Timsort 등

- Non-adaptive: 정렬도와 무관 → 비슷한 성능  
  예시: 선택, 힙, 전통적 병합, 퀵(일반적으로) 등

### 정의

- 적응형 정렬:  
  데이터의 기존 정렬 상태를 감지하고, 그에 따라 수행 과정을 최적화하는 정렬.  
  → 데이터가 정렬되어 있을수록 더 빨라짐.

- 비적응형 정렬:  
  입력의 정렬 여부와 관계없이 항상 동일한 절차를 밟는 정렬.  
  → 데이터가 정렬되어 있어도 복잡도는 변하지 않음.

### 활용도

- 적응형 정렬:  
  실제 환경(로그, 시계열, 데이터베이스 인덱스 등)에서는 부분적으로 정렬된 데이터가 흔함  
  → 대부분의 경우 효율적.

- 비적응형 정렬:  
  데이터의 초기 상태가 예측 불가할 때.  
  항상 안정적이고 균일한 성능을 보장해야 할 때(DBMS, 검색 엔진 등).

## 온라인 알고리즘 (Online) vs 오프라인 알고리즘 (Offline)

### 구분 기준

입력 전체를 미리 알고 있는지, 또는  
입력이 순차적으로 들어올 때 즉시 처리해야 하는지 여부

- Online: 입력에 대해 즉각적으로 순차적으로 처리하는 알고리즘  
  → 최적의 선택 보장 어려움, 대신 실시간 처리 가능.

- Offline: 입력 데이터 전체를 알고 있는 상태에서 처리하는 알고리즘.  
  → 최적의 선택에 유리함, 대신 실시간 처리 불가능.

이러한 알고리즘적 관점의 분류는 정렬에도 적용 가능함.

## 정렬 예시

### 온라인 알고리즘이 적용된 정렬 예시:

- 삽입 정렬 (Insertion Sort):  
  → 데이터가 하나씩 들어올 때 바로 적절한 위치에 삽입

- 힙(Heap) 기반 정렬:  
  → 원소 삽입 시마다 heapify  
  → 현재 입력까지 정렬 상태 유지

- 이진 탐색 트리 기반 정렬:  
  → 입력이 들어올 때마다 트리에 삽입  
  → 중위 순회로 정렬된 결과 조회 가능

### 오프라인 알고리즘이 적용된 정렬 예시

- 퀵 정렬 (Quick Sort)

- 병합 정렬 (Merge Sort)

- 힙 정렬 (Heap Sort)

- 고전 정렬 (선택 / 버블 / 셸 등)

모두 전체 입력을 알고 시작하는 정렬

</details>
<details><summary>버블 정렬 (Bubble Sort)</summary>

## 요약

- 원리: 인접한 두 원소를 비교하여 스왑

- 특징: 비교 기반, 안정적, 제자리, 구현 단순

- 복잡도: 평균/최악 O(n²), 최선 O(n)(조기 종료)

- 활용도: 다른 정렬 사용 추천

## 원리

인접한 두 원소를 비교하여 순서가 잘못되면 스왑하는 비교 기반 정렬

한 번의 패스(전체 순회)가 끝나면 가장 큰 값이 맨 뒤에 고정됨(오름차순 기준)

## 시간·공간·속성

- 시간 복잡도:  
  평균/최악 O(n²), 최선 O(n)(조기 종료 적용 시)

- 공간 복잡도:  
  O(1) (제자리 정렬, in-place)

- 안정성: 안정적(동일 값의 상대 순서 보존)

- 실행 특성: 스왑 횟수가 많아 실제 체감 속도가 느린 편

## 활용처

- 개념 학습: 비교·스왑·패스 개념 설명에 적합

- 거의 정렬된 데이터: 조기 종료가 자주 발생하는 경우

- 작은 입력: 원소 수가 매우 작을 때 간단 구현/시연용

## 한계

- 스왑 비용이 큰 환경에서 특히 비효율적 (데이터 단위의 크기가 큰 경우)

- 입력이 조금만 커져도 O(n²)로 급격히 느려짐 (실 사용 X)

- 동일 난이도라면 삽입 정렬또는 선택 정렬이 더 실용적임

포인터만 변경하는 링크드 리스트의 경우, 스왑 비용은 적지만  
요소에 접근하기 위해 순회하는 비용이 커져서 여전히 비효율적임

## 최적화 로직

- 조기 종료(Early Stopping)
  한 패스 동안 스왑이 없으면 즉시 종료  
  → 최선 O(n) 가능

- 비교 범위 축소(lastSwap 기법)  
  마지막으로 스왑된 위치 이후는 정렬 완료  
  다음 패스에서 해당 인덱스까지만 비교

- 꼬리 구간 생략(고정된 뒤쪽 무시)  
  패스 종료 시 마지막 원소의 위치가 확정되므로,  
  비교 범위를 1씩 줄이는 고정 규칙 적용.

- Cocktail Shaker, Comb, Odd-Even 등 변형이 있음

## 비용 모델(메모리·캐시·분기)

- 메모리: 버블은 스왑 중심 → 쓰기 연산량 많음(스왑당 3회 대입)

- 캐시: 선형 스캔(연속된 인접 원소만 접근)이라 비교 지역성은 좋음

- 분기 예측: 비교-스왑 분기(조건문)가 많아 예측 실패 비용이 누적됨

</details>

<details><summary>선택 정렬 (Selection Sort)</summary>

## 요약

- 원리: 최솟값을 선택해 현재 위치(i)와 스왑

- 복잡도: 비교는 항상 O(n²), 스왑은 최대 n-1

- 성질: 제자리, 불안정, 구현 단순

- 활용도: 쓰기 비용이 매우 큰 환경에서 고려할만함

## 원리

현재 위치 i에서 이후 구간의 최솟값을 찾아  
i와 교환하는 과정을 반복하는 비교 기반 정렬.  
(i = 0 → n-1까지)

한 번의 패스가 끝나면 가장 작은 값이 앞쪽으로 확정됨(오름차순 기준).

## 시간·공간·속성

- 시간 복잡도:
  비교 횟수 ≈ n(n-1)/2 → 최선/평균/최악 모두 O(n²)
  스왑 횟수 ≤ n-1(한 패스에 최대 1회)

- 공간 복잡도:
  O(1) (제자리 정렬, in-place)

- 안정성:
  불안정 정렬(동일 값의 상대 순서가 깨질 수 있음)

## 실행 특성:

비교는 많고, 쓰기(스왑)가 적음 → “쓰기 비용이 비싼 환경”에 적합

## 활용처

- 쓰기 비용이 큰 경우: 데이터 단위가 커 복사 비용이 큰 경우  
  (그래도 n log n 정렬보다는 안좋음)

- 작은 입력: 원소 수가 매우 적은 경우

- 개념 학습: 선택·교환 개념 설명에 용이

## 한계

- 거의 정렬된 경우에도 비교가 줄지 않음

- 대규모 데이터 비적합: O(n log n) 계열(퀵/머지/힙) 대비 현저히 느림

연결 리스트에 적용하면 포인터만 바꿔 스왑 비용은 적지만,  
매 패스마다 최솟값 탐색 순회가 필요해 여전히 O(n²)

## 최적화 로직

- 양방향 선택 정렬(Double Selection):  
  한 패스에서 최솟값과 최댓값을 동시에 찾아 양 끝에 배치  
  → 패스 수는 줄지만 복잡도는 여전히 O(n²)

- 불필요한 스왑 최소화:  
  찾은 최솟값이 이미 제자리면 스왑 생략 → 쓰기 횟수 감소(여전히 ≤ n-1)

- 힙 정렬(Heap Sort)로 확장:  
  선택 과정을 힙(Heap) 자료구조로 구현 → O(log n)

## 비용 모델(메모리·캐시·분기)

- 메모리: 패스당 0~1회 스왑 → 총 스왑 횟수는 n-1 이하

- 캐시:  
  최솟값 탐색이 선형 스캔 중심이므로 공간 지역성이 좋음

- 분기 예측:  
  '현재 최솟값 갱신 여부' 분기가 반복되나, 스왑 분기 빈도는 낮음

</details>

<details><summary>삽입 정렬 (Insertion Sort)</summary>

## 요약

- 원리:  
  배열을 왼쪽(정렬)과 오른쪽(미정렬)으로 나눈 후,  
  오른쪽(미정렬)에서 뽑아, 왼쪽(정렬)의 알맞은 위치에 삽입.

- 복잡도: 평균/최악 O(n²), 최선 O(n)

- 성질: 안정적, 제자리, 작은 입력/거의 정렬된 데이터에 적합

- 활용도: 단독 주력보단 소규모 구간/보조 루틴으로 사용

## 정의

배열을 “정렬된 부분”과 “미정렬 부분”으로 나누고, 미정렬 부분에서 원소를 하나씩 꺼내어  
정렬된 부분의 알맞은 위치에 삽입하여 전체를 정렬하는 알고리즘

## 원리

1. 배열을 두 부분으로 나눔

   - 왼쪽: 이미 정렬된 부분
   - 오른쪽: 아직 정렬되지 않은 부분

2. 미정렬 구간의 첫 원소(i 번째)를 current로 설정

3. 정렬된 부분의 오른쪽 끝( j = i-1 )부터 역방향으로 탐색

4. j > current 일 경우 array[i] = array[j]로 덮어쓴 후 다음 인덱스로 이동( j-- )

5. 4번을 반복하다 올바른 위치에 current 값 삽입.

6. 이 과정을 i = 1 → n-1까지 반복.

덮어쓰면서 이동하기 때문에 기존 원소를 밀어내는 것처럼 표현됨

버블 정렬, 선택정렬과는 다른 덮어쓰기 방식으로 진행됨.

- 1회 이동 = array[j+1] = array[j] = 대입 1회
- 1회 삽입 = array[j+1] = current = 대입 1회

- 불변식: [0..i) 구간은 항상 정렬됨

<details><summary> 구간 표기법</summary>

## 구간 표기법

대괄호 [ 또는 ] → 해당 끝점을 포함한다(inclusive)

소괄호 ( 또는 ) → 해당 끝점을 포함하지 않는다(exclusive)

## [0..i)의 의미

- 0은 포함됨 → 구간 시작점 포함 (0번째 원소는 정렬된 집합에 포함)

- i는 포함되지 않음 → 구간 끝점 제외 (i번째 원소는 아직 정렬 구간에 포함되지 않음)

- “0번 인덱스부터 i-1번 인덱스까지는 항상 정렬돼 있다”

</details>

## 시간·공간·속성

- 시간 복잡도:

  - 최악(역순 배열): 각 원소가 끝까지 밀리므로 총 대입 ≈ n(n-1)/2 + n ≈ O(n²)
  - 최선(이미 정렬): 각 단계에서 삽입만 1회 → 총 대입 ≈ n

- 공간 복잡도: O(1) (제자리 정렬, in-place)

- 안정성: 안정적(동일 키의 상대 순서 보존)  
  구현 시 > 비교만 사용(동일 값 원소의 상대적 순서 유지)

- 실행 특성: 이동(shift) 중심이라 인접 메모리 쓰기 → 캐시 친화적

- 작은 입력·거의 정렬된 데이터에서 체감 성능이 좋음

## 활용처

- 작은 데이터셋: 상수항이 작아 실사용에서도 빠르게 동작

- 거의 정렬된 데이터: 최선 O(n)에 근접

- 하이브리드 정렬 보조 루틴: 퀵/머지/팀소트 등에서 작은 입력 처리

## 한계

- 무작위·역순 데이터에서는 이동이 많아 성능이 안좋음(O(n²))

- 대규모 데이터에서 O(n log n) 계열보다 성능이 안좋음

- 연결 리스트: 삽입 자체는 O(1) 이지만, 위치 찾기 순회가 필요함 (전체 O(n²))

## 최적화 방법

- 조기 종료:  
  왼쪽 탐색 중 현재 원소 ≤ 키를 만나면 즉시 중단 → 이미 그 앞은 모두 ≤ 키  
  이미 정렬된 배열에서 비교 n-1회, 이동 0회 → O(n)

- 이진 탐색 삽입(Binary Insertion Sort):  
  삽입 위치 탐색을 이진 탐색(O(log n))으로 수행  
  → 비교 횟수 감소, 전체는 여전히 O(n²)

  비교가 비싼 환경(복잡한 키 비교)에서 유의미

- 셸 정렬(Shell Sort)로 확장:  
   멀리 떨어진 원소 정렬시 많은 이동이 필요하다는 기존의 단점을 보완.  
   \
   간격(gap) 을 두고 떨어진 원소들끼리 먼저 부분 정렬한 뒤,  
   점점 간격을 줄여가면서 전체를 정렬하는 알고리즘  
   → O(n^(3/2)) ~ O(n log² n) 수준까지 개선 가능 (최악은 구현/시퀀스에 따라 O(n²))

- 센티넬(Sentinel) 기법:
  배열 맨 앞에 "절대 최소값"을 넣어두고,  
  반복문에서 경계 검사(j >= 0)를 없애는 방식.  
  → index 검사를 기존 비교 조건으로도 수행할 수 있도록 만드는 트릭

## 비용 모델(메모리·캐시·분기)

- 메모리: 연속 이동(shift) → 스왑 대비 쓰기 패턴이 효율적

- 캐시: 왼쪽으로 연속 접근하므로 공간 지역성↑

- 분기 예측: 크기 비교 단일 분기 반복 → 정렬될수록 예측 성공률↑

</details>

<details><summary>병합 정렬 (Merge Sort)</summary>

## 요약

- 원리 : 분할(반씩 쪼갬) → 정복(각자 정렬) → 병합(두 정렬된 리스트를 합침)

- 시간 복잡도: 항상 Θ(n log n) (최선/평균/최악 동일)

- 공간 복잡도:

  - 배열:  
    버퍼 - Θ(n), 스택 - 재귀 O(log n) / 총 - O(n)
  - 연결 리스트:  
    버퍼 - O(1), 스택 - 재귀 O(log n) / 반복 O(1), 총 - 최대 O(1)

- 안정성: 안정 정렬(동일 키의 상대 순서 보존; 동등비교 시 왼쪽 우선 선택)

- 활용: 대용량/안정성 요구 환경, 외부 정렬(디스크), 하이브리드 정렬

함수 호출 스택이란?

## 원리(분할·정복)

lo: 구간의 시작 인덱스 (low)  
hi: 구간의 끝 인덱스 (high)  
mid: 구간의 가운데 인덱스 (middle)

### 분할(Divide)

배열을 왼쪽 A[lo..mid], 오른쪽 A[mid+1..hi] 와 같이 분할

분할 자체는 인덱스 연산 → O(1)

### 정복(Conquer)

두 하위 배열에 동일한 분할 알고리즘을 재귀/반복 적용

길이가 0 또는 1이면 (기저조건) 이미 정렬되었다고 간주 후 재귀 종료.

### 병합(Merge)

정렬된 두 구간을 두 포인터로 한 번 훑으며 합침

한쪽이 소진되면 나머지 전부 복사

### 병합의 불변식

결과 배열의 접두사(prefix)는 항상 정렬됨

다음 후보는 왼쪽 i, 오른쪽 j의 최소값 중 하나

동등 비교 시 왼쪽을 먼저 택하면 안정성 보장

시간 분석 직관

병합은 각 원소를 정확히 한 번 출력 → Θ(n)

재귀 트리 깊이 log₂ n, 각 레벨에서 총 작업량 n → n log n

## 시간·공간·속성

- 시간: 최선/평균/최악 Θ(n log n) → 성능이 일정함

- 공간:

  - 배열: 버퍼 Θ(n), 재귀 스택 O(log n),
    Bottom-up(반복) + 공유 보조배열(aux) 로 스택 제거 가능

  - 연결 리스트: 버퍼(포인터 재연결) O(1)

- 안정성: 안정적

- 적응성: 기본형은 비적응적, “런(run) 감지”로 보완 가능

## 활용처

- 안정성이 필요한 대규모 정렬

- 외부 정렬(External Sort): 메모리 크기를 초과한 데이터 정렬(로그, 트랜잭션)

- 연결 리스트 정렬: 포인터 재배치

- 하이브리드 정렬: Timsort 등에서 런 감지 + 병합

## 최적화

- 작은 구간 삽입 정렬(Threshold): 작은 구간은 삽입 정렬로 처리 → 상수항 절감

- 이미 정렬이면 병합 생략: left.last ≤ right.first면 O(n) 병합 생략

- 보조배열 재사용: 호출마다 새 배열 대신 공유 aux 사용 → 할당/복사 비용 감소

- Bottom-up(반복형): run 크기 1,2,4,8…로 키워가며 인접 블록 병합 → 스택 오버헤드 0, 캐시 친화 개선

- 자연 병합(Natural Mergesort): 입력에서 증가/감소 런을 감지해 바로 병합 → 실효 성능↑(팀소트의 핵심)

- 연결 리스트 분할/병합: slow/fast로 중앙 분할, 포인터만 재연결해 안정 병합

- 외부 정렬 최적화: k-way merge(힙) 로 I/O 최소화, replacement selection으로 더 긴 run 생성

- 병렬화: 좌/우 분할을 병렬 처리, 병합도 분할 병합으로 병렬화(워크 스틸링 등)

- 센티넬 사용: 경계 체크 분기 제거(저수준 언어에서 유용)

## 비용 모델(메모리·캐시·분기)

- 메모리: 배열은 버퍼 왕복 복사가 필요 → 쓰기량 큼(보조배열 재사용으로 완화)

- 캐시: 병합은 선형 스트리밍 읽기/쓰기 → 캐시/디스크 접근 패턴에 유리

- 분기 예측: 두 포인터 비교 분기 반복. 런 감지/병합 생략으로 분기 수 자체를 줄일 수 있음

</details>

<details><summary>퀵 정렬 (Quick Sort)</summary>

## 요약

- 원리: 임의의 피벗(pivot)을 기준으로 값 분할(partition) → 좌/우 구간에 재귀 적용(분할 정복)

- 시간 복잡도: 평균/보통 Θ(n log n), 최악 Θ(n²)(나쁜 분할 연속 시 - 분할 시 원소 쏠림)

- 공간 복잡도: O(log n)(재귀 스택 제어 방식에 따라 최악 O(log n)까지 제한 가능)

- 안정성: 불안정(기본) / 안정(안정 파티션 + 추가 공간 O(n) 필요 - 보조배열 활용)

- 활용도: 대부분의 인-메모리 정렬 상황, 안정성 필요X, 중간규모 데이터에 적합

## 원리(분할·정복)

- 분할: 피벗보다 작은 요소와 큰 요소로 배열을 제자리(in-place) 재배치

- 정복: 분할된 두 구간을 같은 방식으로 정렬

- 결합: 퀵정렬은 병합 단계가 사실상 없음(분할 시 재배치가 끝)

## 파티션

- 정의:  
  배열을 피벗을 기준으로  
  [ 작은 값들 | (피벗과 같은 값들) | 큰 값들]  
  형태로 재배치해, 피벗(구간)이 최종 정렬된 위치에 놓이도록 만드는 절차.  
  → 이후 파티션 양쪽 값 재귀 정렬 후 병합

- 공통 불변식: 스캔이 진행되는 동안,
  - 왼쪽 블록: 피벗보다 작은 값들
  - 가운데(선택적): 피벗과 같은 값들(3-way인 경우)
  - 오른쪽 블록: 피벗보다 큰 값들

스캔 포인터가 앞으로 나아가도 구간 구분은 항상 유지

## 대표 파티션 방식

### Lomuto 파티션

- 특징: 피벗을 구간의 끝에 두고(A[high]) 왼쪽에서 오른쪽으로 스캔(for j = low to high - 1:)  
  → 작은 원소들을 앞쪽으로 스왑하며 피벗보다 작은 구간을 넓혀감

- 장점: 구현이 단순함

- 단점: 불필요한 스왑이 많고 분기 예측에 취약 → 실측상 느린 편

- 불변식 요지: 스캔 인덱스 앞쪽은 [< pivot] / 나머지는 [≥ pivot]

      LomutoPartition(A, low, high):
      pivot = A[high] // 피벗은 배열 끝 원소
      i = low - 1 // i = 피벗 이하 구간의 끝 인덱스
      for j = low to high - 1: // j = 검사할 인덱스
          if A[j] <= pivot: // 검사한 인덱스가 피벗 이하라면
              i = i + 1 // 이하 구간 1칸 확장
              swap A[i] <-> A[j] // 이하 구간의 끝으로 스왑
      swap A[i+1] <-> A[high] // 마지막으로 피벗을 이하 구간 끝과 스왑
      return i+1   // pivot의 최종 위치

### Hoare 파티션 (양끝)

- 특징: 양끝 포인터가 안쪽으로 이동하며 잘못된 쌍을 발견하면 교환

- 장점: 스왑 수가 적고 실제 성능이 좋은 경우가 많음

- 주의:  
  pivot과 동일한 값이 여러 개 있을 수 있고,  
  pivot을 고정시키지 않고 경계만 나누기 때문에,  
  반환 위치가 피벗 최종 인덱스와 일치하지 않을 수 있음  
  → 이후 재귀 범위 지정 주의

      HoarePartition(A, low, high):
      pivot = A[low]          // 보통 첫 원소
      i = low - 1 // 왼쪽 끝
      j = high + 1 // 오른쪽 끝
      while true:
          repeat i = i + 1 until A[i] >= pivot // 이하 구간에서 이상 값 탐색
          repeat j = j - 1 until A[j] <= pivot // 이상 구간에서 이하 값 탐색
          if i >= j: return j // i ≥ j가 되면 j를 반환 → 분할 경계
          swap A[i], A[j] // 잘못된 쌍 교환

### 원리:

이하 구간에서 이상 값 발견 시 멈추고, 이상 구간에서 이하 값 발견시 멈춤 → 잘못된 쌍 교환

### 3-way 파티션 (Dutch National Flag)

구간을 < pivot / = pivot / > pivot 세 부분으로 즉시 분할

중복 원소(키)가 많을 때 유리함 (예시: [3,3,3,3,3]은 한 번에 처리)

안정성은 보장하지 않지만, 중복 처리에 유리함

### 불변식

- a[lo .. lt-1] : < pivot

- a[lt .. i-1] : = pivot

- a[i .. gt] : 미확인(?)

- a[gt+1 .. hi] : > pivot

### 포인터 약자

- lt = less-than 경계(“< 구간의 끝 다음 칸”)

- gt = greater-than 경계(“> 구간의 시작 직전 칸”)

- i = 현재 검사 중인 인덱스

### 처리 규칙 (선형 스캔)

- a[i] < pivot → swap(a, lt, i); lt++; i++; (< 구간 확장)

- a[i] == pivot → i++; (= 구간 확장)

- a[i] > pivot → swap(a, i, gt); gt--; (> 구간 확장; i는 재검사)

i > gt가 되면 세 구역 완성

      function swap(a, i, j) {
        // 배열 a에서 i, j 위치 교환
        const t = a[i];
        a[i] = a[j];
        a[j] = t;
      }

      function partition3way(a, lo, hi, cmp = (x,y)=>x<y?-1:x>y?1:0) {
        let lt = lo,    // pivot보다 작은 구간의 끝 다음 위치
        i  = lo + 1,    // 현재 검사 중인 인덱스
        gt = hi;        // pivot보다 큰 구간의 시작 직전 위치
        const pivot = a[lo]; // 왼쪽 끝 = 피벗
        while (i <= gt) {
          const c = cmp(a[i], pivot); // 현재 값과 피벗 비교
          if (c < 0) swap(a, lt++, i++); // 스왑 후 작은 구간 확장 + 검사 인덱스 증가
          else if (c > 0) swap(a, i, gt--); // 스왑 후 큰 구간 확장 + 인덱스 유지
          (맨 뒤 원소와 교환했으므로 다음 검사때 같은 인덱스를 검사해야함)
          else i++; // 동일 값인 경우 다음 인덱스 검사
        }
        // equal block 범위 [lt, gt] 반환
        // 이 구간은 pivot과 같은 값들이 모여 있고, 정렬이 이미 끝난 상태
        return { lt, gt };
      }

## 시간·공간·속성

- 시간: 평균/보통 Θ(n log n), 최악 Θ(n²)(극단적 분할: 1 vs n-1)

피벗 선택과 3-way 사용으로 최악 확률을 크게 낮춤

- 공간(스택): 평균 O(log n)  
  “작은 쪽 먼저 재귀 + 큰 쪽은 루프로(꼬리 재귀 제거)”  
  → 최악도 O(log n) 로 제한

- 안정성: 불안정

안정이 필요하면 안정 파티션(추가 버퍼) 또는 다른 정렬(팀소트/병합)을 고려

## 퀵정렬의 대표적 “종류/변형”

### 파티션 방식

- Lomuto: 단순, 스왑 많음(교육/참고용)

- Hoare: 실 성능 우수, 단 피벗 위치가 아닌 경계 반환

- 3-way: 중복 키 많을 때 최고 선택

## 최적화

### 피벗 전략

- 고정 피벗(첫/끝): 구현 간단하나 최악 빈번

- 랜덤 피벗: 평균적 균형 개선, 편향 데이터 방지

- Median-of-3(첫/중간/끝의 중앙값): 극단 분할 완화, 상수항 개선

- Tukey’s ninther: median-of-3을 3번 후 중앙값 → 매우 견고

- Median-of-Medians(선형시간 선택): 최악 O(n log n) 보장 가능(상수항 큼; 학술/특수용)

### 하이브리드 정렬

- 인트로소트(Introsort):  
  퀵정렬 시작 → 깊이 한도 초과 시 힙정렬로 전환

- 작은 구간 삽입정렬:  
  작은 구간은 삽입 정렬로 처리(상수항 절감)

- 듀얼-피벗 퀵정렬:  
  두 피벗으로 3구간 분할

## 비용 모델(메모리·캐시·분기)

- 메모리 :  
  스왑 중심(버블보다 적고, 병합보다 훨씬 적음)

- 캐시 :  
  제자리 + 양끝→중앙 스캔으로 지역성 양호(무작위 스왑은 불가피)

- 분기 예측:  
  파티션의 다수 분기가 실속도 좌우 → 3-way/샘플링/블록화로 완화

## 다른 정렬과 비교

- 병합 정렬: 항상 Θ(n log n) + 안정 + 외부정렬/연결리스트에 강함 / 추가 메모리 필요

- 퀵정렬: 보통 더 빠른 상수항/캐시 효율, 최악 O(n²)(하이브리드로 보완)

- 힙 정렬: O(n log n) + O(1) 공간 + 최악 보장 / 캐시·상수항 불리 → 실측은 퀵 < 힙

- 삽입/선택: O(n²) 계열, 작은 구간에서만 보조로 유리

## 활용처

- 메모리 내 정렬이 거의 다 됐을 때(특히 참조/기본형의 큰 배열)

- 안정성이 꼭 필요하지 않을 때

- 중복 키가 많다면 3-way를 우선 고려

- 최악 보장이 필요하면 인트로소트(퀵 + 힙 fallback)

</details>

<details><summary>상수항과 상수계수</summary>

- 참조:  
  https://usaco.guide/bronze/time-comp?lang=cpp  
  https://en.wikipedia.org/wiki/Time_complexity  
  https://stackoverflow.com/questions/22614585/what-is-constant-factors-and-low-order-term-in-algorithms

## 정의

### 상수항(Constant term):

입력 크기 n과 무관하게, 알고리즘 구현 중  
 실행하지 않으면 안되는 처리들이 낳는 비용을 모두 합친 더하기 항.  
 (고정 횟수로 수행되는 초기화/마무리, 소규모 I/O, 상수 크기 메모리 할당 등)

### 상수계수(Constant factor):

입력 크기와 무관하게, 알고리즘의 핵심 단계가 한 번 실행될 때마다 발생하는 고정 비용의 합.

Stack Overflow

      입력 크기에 무관하게 반복되는 핵심 연산당 곱해지는 상수 값. 실질 속도에 영향을 줌.
      Stack Overflow

위키백과

      연산 1회당 고정 시간으로, 지배항 앞에 등장하는 상수.	Wikipedia

USACO Guide

      같은 시간복잡도라도 연산 종류나 구현에 따라 다르게 나타난다.	USACO Guide

### 예시

- T(n) = an + c → O(n) 에서 상수계수 = a, 상수항 = c

- T(n)=a nlogn + bn + c → O(nlogn) 에서 상수계수 =a

* 상수항 / 상수계수 최적화:  
  차수는 그대로 두되 a,b,c 를 줄여 실제 시간을 빠르게 만드는 것

## 성능에 미치는 영향

### 알고리즘 간 상수 계수 차이

같은 빅오라도 구현 상수 계수 차이로 실측 속도가 달라짐.

### 예시

퀵정렬과 병합정렬은 둘 다 O(nlogn)이지만,  
비교·이동·메모리 사용·캐시 지역성 등 상수 비용의 차이로 실측 성능이 달라짐

### 최적화 예시

- 입력 특성(메모리 제약, 안정성, 정렬도)에 맞는 알고리즘 선택.

- 실측 기반 선택(마이크로벤치, 프로파일링).

## 상수항 최적화가 효과적일 때

- 차수 개선이 어렵거나 이미 최적일 때  
  → 방법론 적으로는 더이상 개선이 어려울 때

- 짧은 입력 범위/짧은 런타임(치명적 상수비용이 전체의 대부분).

- I/O 바운드/메모리 바운드 상황(차수보다 고정 지연이 지배).

### 주의사항

- 가독성과 안전성 고려
- 프로파일링으로 확인된 병목 지점에만 적용

## 연산 단위 비용

### 정의

기본(단위) 연산 1회의 비용.  
(덧셈/곱셈/비교/분기 등)

### 최적화 예시

- 비교·대입을 줄인 코드 경로 선택.
- 조건문 대신 수학/비트 연산으로 대체 (분기 제거).
- 고비용 연산을 저비용 연산으로 대체 (나눗셈 → 시프트/곱셈).

## 메모리 접근 비용

### 정의

동일 연산이라도 메모리 배치/캐시 적중률에 따라 달라지는 상수 비용  
→ 캐시 친화도 차이에 따른 상수 비용

### 최적화예시

- 데이터 레이아웃 정리: 순차 접근, struct 및 패딩 최소화
- 블록/타일링: 타일 단위로 접근해 캐시 재사용 극대화.

## 루프·함수 호출 오버헤드

### 정의

루프 제어(i++, 조건 확인 등)나 함수 호출 스택 관리 비용  
(루프 인덱스 증가, 경계 체크, 함수 호출 프롤로그/에필로그 같은 제어 비용 등)

### 최적화 예시

- 루프 전개(loop unrolling)
- 인라이닝(inlining)
- 경계 체크 제거
- 재귀를 반복으로 대체(스택 프레임 비용 절감).

## I/O 오버헤드:

### 정의

디스크/네트워크 접근 시 발생하는 기본 지연(latency)

### 최적화 예시

- 배치/버퍼링/블록 사용
- 비동기 I/O / 이중 버퍼링
- 순차 I/O 위주로 설계(랜덤 접근 회피).

## 분기(branch) 비용

### 정의

분기 예측 실패 시 파이프라인 flush로 발생하는 비용

### 최적화 예시

- 불필요한 if 제거
- 데이터 재배열(정렬해 편향 강화)
- 분기 없는 연산 사용
- 조건의 빈도 높은 경로를 핫패스로.

## 할당/해제 및 동기화 오버헤드

### 정의

메모리 관리(malloc/new/free, GC)와 락/원자 연산의 고정 비용.

### 최적화 예시

- 풀링(pooling)
- Arena/Region alloc
- 락 범위 축소
- 락 없는 구조(CAS, ring buffer) 채택.

## 언어/런타임 상수 비용 (이해 안됨)

### 정의

언어/런타임이 제공하는 안전성·동적 기능 때문에 생기는 부가 비용  
(바운드 체크, 가상 호출, 인터프리터/VM, 박싱/언박싱 등)

### 예시

- Java/Kotlin/Rust: 배열 범위 체크가 루프마다 수행
- C++/Java/C#: 가상 함수 호출로 인한 간접 분기(예측 어려움)
- Python/JS: 동적 타입 + 인터프리터 오버헤드, 객체 박싱
- GC 언어: 할당 빈번 + write barrier로 상수 증가

### 최적화 예시

- 체크 제거 유도: 인덱스 범위를 컴파일러가 유추하도록 루프 구조 단순화, 길이 사전 검증

- 탈가상화/디스패치 단순화: 모노모픽 호출 유지, final/sealed/CRTP로 devirtualization 유도

- 인라이닝·벡터화가 잘 먹히게 코드 패턴 단순화

- 박싱 회피: 원시 타입 컬렉션 사용, escape analysis로 스택 할당 유도

- JIT/VM: 워밍업 비용을 배제한 상태에서 성능 측정(steady state)

</details>
<details><summary>깊이 우선 탐색 (DFS, Depth-First Search)</summary>

## 정의

한 노드를 시작점으로 하여, 가능한 한 깊숙이 들어가며 탐색하는 방식.

더 이상 내려갈 곳이 없을 때 뒤로 되돌아와 다른 경로를 탐색함(backtracking).

트리/그래프 같은 연결 구조에서 경로·구조적 속성 파악에 강함.

## 전제조건

- 노드와 간선으로 구성된 비선형 구조(그래프/트리).
- 깊이(depth) 개념이 성립해야 함.

## 구현

- 스택 기반:  
  명시적으로 선언한 스택을 활용하는 방식  
  코드가 장황해질 수 있지만, 스택 한도 안전
- 재귀 호출:  
  호출 스택을 암묵적인 스택으로 활용하는 방식  
  코드가 간결해지지만, 깊으면 스택 한도 위험

## 절차

1.  시작 노드를 방문하고 스택에 push / 재귀 진입
2.  미방문 인접 노드가 있으면 이동해 push / 재귀
3.  더 이상 미방문 노드가 없으면 pop / 복귀 후, 다른 분기 시도
4.  모든 노드가 방문될 때까지 반복

        A 방문 → stack=[A]

        A pop → 인접 B,C push → stack=[C,B]

        B pop → 인접 E,F push → stack=[C,F,E]

        E pop → 리프 → 끝 → stack=[C,F]

        F pop → 리프 → 끝 → stack=[C]

        C pop → 인접 G,H push → stack=[H,G]

        … 반복

## 예시

### DFS(재귀)

u: 현재 정점(노드)  
v: 그 이웃  
w: 또 다른 정점 …

      function dfs(u, adj, visited) {
        visited[u] = true;  // 발견 시점에 표시
        for (const v of adj[u]) {
          if (!visited[v]) dfs(v, adj, visited);
        }
      }

### DFS(스택)

s = 탐색 시작점  
adj = s와 연결된 노드 목록

      function dfsIter(s, adj, visited) {
        const stack = [s];  // = stack.push(s);
        visited[s] = true;
        while (stack.length) {
          const u = stack.pop();
          for (const v of adj[u]) { // push 전에 방문 표시
            if (!visited[v]) { visited[v] = true; stack.push(v); }
          }
        }
      }

### Visted 배열의 스코프

- 일회성 탐색: 함수 내에서 호출할 때마다 초기화(해당 호출 내에서만 유효)
- 연속 탐색: 전역으로 유지 → 이전 호출에서 방문한 노드 재탐색 X

## 방문 표시

- 같은 노드를 다시 처리하지 않게 막는 안전장치
  → 중복 방문/무한 루프 방지

- 각 노드로의 경로가 유일할 때 생략 가능하지만, 시작노드는 필수로 체크해야함  
  (root로 복귀시 탐색이 끝난 자식 노드재방문 방지)

- 미방문 노드 발견 시점(push/재귀 진입 직전)에 visited=true로 표시  
  → 같은 노드를 두 번 push하는 경우를 원천 차단.

- 정점이 0..Length-1 인덱스일 때: 불리언 배열로 관리하는게 효율적

- 정점이 문자열 / 객체 ID일 때: 집합, 맵이 효율적  
  (visited.has(id) / visited.add(id) 처럼 id로 체크)

## 특징

- 시간 복잡도: (V=노드 수, E=간선 수)  
  인접리스트에서 O(V+E)  
  인접행렬에서 O(V²)

- 공간 복잡도:  
  visited 배열 / 집합(set, map)에서 O(V)  
  탐색 스택 / 재귀 호출 스택에서 최악 O(V)

- 성질:  
  최단 경로 보장 X  
  경로/사이클/위상/연결성 등 구조 분석에 유리함

## 활용

- 경로·도달성: 특정 목적지까지 도달 가능한가?

- 사이클 탐지: 방향/무방향 그래프 순환 여부 확인

- 위상 정렬, 강연결요소(SCC) (Tarjan, Kosaraju)

- 백트래킹: 퍼즐/조합(예: N-Queen, 부분집합/순열 생성)

</details>
<details><summary>너비 우선 탐색 (BFS, Breadth-First Search)</summary>

## 정의

같은 레벨(계층)의 노드들을 모두 방문한 후, 다음 레벨로 진행하는 방식.

"출발점으로부터의 거리"가 가까운 순서대로 탐색.

트리/그래프 같은 연결 구조에서만 의미 있음.

## 전제조건

- 노드와 간선으로 구성된 비선형 구조(그래프/트리).
- 깊이(depth) 개념이 성립해야 함.

## 구현

큐(queue) 자료구조 사용.  
(큐와 동일한 기능을 보장한다면 모두 가능)

    // start: 배열 = index(숫자), 객체 = 키
    function bfs(start) {
      let queue = [start];
      visited[start] = true;  // enqueue 전 방문 체크

      while (queue.length > 0) {
        let node = queue.shift();
        for (let next of graph[node]) { // 인접 노드 순회
          if (!visited[next]) {
            visited[next] = true;  // 큐에 push 전 방문 처리
            queue.push(next);
          }
        }
      }
    }

    // 객체
    let visited = {};         // 객체
    let start = "A";          // 정점 이름이 문자열일 수도 있음
    visited[start] = true;    // 키 "A"에 true 기록

    // 맵
    let visited = new Map();

    visited.set(1, true); // 숫자 키
    console.log(visited.get(1));  // true

    visited.set("A", true); // 문자열 키
    console.log(visited.get("A"));  // true

    let node = { id: 42 }; // 객체 키
    visited.set(node, true);

## 절차:

1. 시작 노드를 방문하고 큐 enqueue

2. 큐에서 노드를 꺼내면서 인접 미방문 노드를 enqueue

3. 큐가 빌 때까지 반복

- 큐에 넣을 때 방문 여부를 체크해야 중복 탐색 방지 가능.

      A 방문 → queue=[A]

      A dequeue → 인접 B,C enqueue → queue=[B,C]

      B dequeue → 인접 D,E enqueue → queue=[C,D,E]

      C dequeue → 인접 F,G enqueue → queue=[D,E,F,G]

      … 반복

## 복잡도

- 시간 복잡도: O(V+E)

- 공간 복잡도: 큐 = O(V) 최악

## 특징

- 항상 최단 경로(간선 가중치가 동일할 때)를 보장

- 같은 레벨의 노드를 한 번에 탐색

## 활용

- 최단 경로 탐색: 미로 최단 거리, 네트워크 hop 수

- 계층적 문제: 레벨 순회(level-order traversal), 친구 추천 알고리즘

- 네트워크 탐색: Flood Fill (페인트 채우기), 웹 크롤러

- 상태 탐색: 퍼즐/게임에서 최소 이동 횟수 찾기

</details>

</details>
